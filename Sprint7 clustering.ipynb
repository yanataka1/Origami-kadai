{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint7 クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D2SiOgfCSBhk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スクラッチクラスの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qY0jAkPISBhk"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-de8b4a88d979>, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-de8b4a88d979>\"\u001b[1;36m, line \u001b[1;32m88\u001b[0m\n\u001b[1;33m    cluster = np.zeros(len(X))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ScratchKMeans():\n",
    "    \"\"\"KMeansクラスタリングのスクラッチ\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=2,n_init=20,n_iter=100,verbose=False):\n",
    "        \"\"\"\n",
    "        Scratch implementation of K-means\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_clusters : クラスタ数\n",
    "        n_init : 何回初期化するか\n",
    "        max_iter : 各初期化毎に何回学習させるか\n",
    "        verbose : 学習状況を出力するか否か\n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        # SSE（誤差）を小さくする方向に学習（更新）させていくため、初期値は大きいものを用意しておく\n",
    "        self.best_sse = 10**20\n",
    "        \n",
    "    def _update_myu(self,X):\n",
    "        \"\"\"中心点の更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        self.pre_myu = self.myu\n",
    "        # クラスタ数でループ\n",
    "        for j in range(self.n_clusters):\n",
    "            # ループ中のクラスタに該当する説明変数の値の平均値を新しい中心点とする\n",
    "            self.myu[j] = np.mean(X[X[:,-1]==j,:-1],axis=0)\n",
    "        \n",
    "    def _update_cluster(self,X):\n",
    "        \"\"\"クラスタの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # データ数でループ\n",
    "        for i in range(len(X)):\n",
    "            # 比較のための初期値\n",
    "            dist_m = 10**20\n",
    "            # クラスタ数でループ\n",
    "            for j in range(self.n_clusters):\n",
    "                # 該当クラスタの中心点との距離を計算\n",
    "                dist = np.sqrt(np.sum((X[i,:-1])-self.myu[j]**2))\n",
    "                # 前回保存した（あるいは初期値）より距離が小さければ、そちらのクラスタを採用\n",
    "                if dist < dist_m:\n",
    "                    dist_m = dist\n",
    "                    X[i,-1] = j\n",
    "                    \n",
    "    def calc_sse(self,X):\n",
    "        \"\"\"SSEの計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # SSEの計算\n",
    "        sse = 0\n",
    "        # データ数でループ\n",
    "        for i in range(len(X)):\n",
    "            # クラスタ数でループ\n",
    "            for j in range(self.n_clusters):\n",
    "                # 末尾のクラスタを判定し、該当クラスタならsseに加算\n",
    "                if j == X[i,-1]:\n",
    "                    # ベクトルの距離（ノルム）計算＊末尾のクラスタを除いた数値を使用している点に注意\n",
    "                    sse += np.sum((X[i,:-1]-self.myu[j])**2)\n",
    "        # sseが改善していれば、更新\n",
    "        if self.best_sse > sse:\n",
    "            self.best_sse = sse\n",
    "            self.record_myu = self.myu\n",
    "            self.record_cluster = self.n_clusters\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # 初期化回数分ループ\n",
    "        for i in range(self.n_init):\n",
    "            \n",
    "            # データXからクラスタ数分の初期値をランダムにとってくる(各クラスタの初期の中心点)\n",
    "            self.myu = X[np.random.choice(len(X),size=self.n_clusters,replace=False)\n",
    "        \n",
    "            # Xベクトルにクラスタ列を追加（クラスタは0で初期化）\n",
    "            cluster = np.zeros(len(X))\n",
    "            X_cluster = np.concatenate([X,cluster.reshape(-1,1)],axis=1)\n",
    "            \n",
    "            # 最大学習回数分ループ\n",
    "            for j in range(self.n_iter):\n",
    "                # SSEを更新\n",
    "                self.calc_sse(X_cluster)\n",
    "\n",
    "                # クラスタ更新\n",
    "                self._update_cluster(X_cluster)\n",
    "                \n",
    "                # クラスタの中心点の更新\n",
    "                self._update_myu(X_cluster)\n",
    "                \n",
    "                # 学習状況の出力（グラフ）\n",
    "                if self.verbose:\n",
    "                    print(\"初期化：%s　学習回数：%s　最善のSSE：%s\"%(i,j,self.best_sse))\n",
    "                \n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # 予測値の初期化\n",
    "        y_pred = np.zeros(len(X))\n",
    "        # 処理の流れ自体は、_reclustering関数と同様\n",
    "        # データ数でループ\n",
    "        for i in range(len(X)):\n",
    "            # 比較のための初期値\n",
    "            dist_m = 10**20\n",
    "            # クラスタ数でループ\n",
    "            for j in range(self.record_cluster):\n",
    "                # 該当クラスタの中心点との距離を計算\n",
    "                dist = np.sqrt(np.sum((X[i]-self.record_myu[j])**2))\n",
    "                # 前回保存した（あるいは初期値）より距離が小さければ、そちらのクラスタを採用\n",
    "                if dist < dist_m:\n",
    "                    dist_m = dist\n",
    "                    y_pred[i] = j\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w_S3ZtcSBhm"
   },
   "source": [
    "# 事前準備：データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJKWNLwbSBhp"
   },
   "outputs": [],
   "source": [
    "# Simple Data Set 3\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, _ = make_blobs(n_samples=100,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=0.5,\n",
    "                  shuffle=True,\n",
    "                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "39pGXIekSBhq",
    "outputId": "674744c5-97c4-4e20-a47b-07498e2e1ed4"
   },
   "outputs": [],
   "source": [
    "# Data Distribution Visualization\n",
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.scatter(X[:,0],X[:,1],s=80);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid = \\\n",
    "train_test_split(X,train_size=0.8,random_state=None)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1\n",
    "\n",
    "スクラッチコード86行目\n",
    "\n",
    "`self.myu = X[np.random.choice(len(X),size=self.n_clusters,replace=False)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2\n",
    "\n",
    "53行目：`def calc_sse(self,X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3\n",
    "\n",
    "34行目：`def _update_cluster(self,X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4\n",
    "\n",
    "22行目：`def _update_myu(self,X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5\n",
    "\n",
    "83行目：`for i in range(self.n_init):`\n",
    "\n",
    "93行目：`for j in range(self.n_iter):`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ScratchKMeans(n_clusters=4,n_init=5,n_iter=100,verbose=True)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_valid)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow = {}\n",
    "for k in range(1,8):\n",
    "    model = ScratchKMeans(n_clusters=k,n_init=5,n_iter=100,verbose=False)\n",
    "    model.fit(X)\n",
    "    elbow[k] = model.best_sse\n",
    "\n",
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.plot(list(elbow.keys()),list(elbow.values()),'rs--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備：データ作成＆PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "data = pd.read_csv('Wholesale customers data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主成分分析結果の可視化\n",
    "# サンプルコードの実行\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=None)\n",
    "pca = pca.fit(data)\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(cum_var_exp)\n",
    "plt.bar(range(1,9), var_exp, alpha=0.5, align='center')\n",
    "plt.step(range(1,9), cum_var_exp, where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.hlines(0.7, 0, 6,  \"blue\", linestyles='dashed')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題10,11,12に関しては、考察系のため回答例の紹介は省略します。\n",
    "\n",
    "\n",
    "**卸売業者にとって有益な情報**を求めたいという目標があるため、それを前提に分析を行っていきます。\n",
    "\n",
    "**卸売業者にとって有益な情報**を次のように設定する\n",
    "\n",
    "顧客をいくつかのクラスターに分け、そのクラスターの特性に合ったサービスを創出していきたい\n",
    "\n",
    "こういうビジネス的な施策を考える上での分析では、エルボー法やシルエット図のようないわゆる学問的なクラスタ数の決定方法より、ビジネスとしての実現可能性の方が重視されることが多い。\n",
    "\n",
    "\n",
    "+ 任意のクラスタ数を決定(8つのクラスタに分けたところで、施策やサービスを8種類用意できると思わない)\n",
    "+ クラスターに分ける\n",
    "+ 各クラスターの傾向を見る\n",
    "+ 施策を考える\n",
    "+ 結果論的に施策が似ているクラスタは合体させる"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ur_dH43_SBh5",
    "QEIbvdR5SBh6"
   ],
   "name": "mep_day14_clustering_en.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "768px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
