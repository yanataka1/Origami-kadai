{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5c3968",
   "metadata": {},
   "source": [
    "# 線形回帰の学習と推定\n",
    "\n",
    "## ゴール\n",
    "- **【Sprint 機械学習スクラッチ 線形回帰】の【問題６】を解くうえで必要な知識や技術について理解する**\n",
    "\n",
    "### Sprintの目的\n",
    "- 線形回帰の学習法について理解する\n",
    "- 学習法の実装法ついて理解する\n",
    "\n",
    "## どのように学ぶか\n",
    "\n",
    "【Sprint 機械学習スクラッチ 線形回帰】の【問題6】と照らし合わせながら、進めていきましょう。\n",
    "\n",
    "## 学習と推定\n",
    "\n",
    "ここまでの問題では、下記の関数を作成してきました。\n",
    "\n",
    "`_linear_hypothesis`：仮定関数の出力計算\n",
    "\n",
    "`_gradient_descent`：$\\theta$の更新\n",
    "\n",
    "この問題では、この2つの関数を利用し(変更可)、冒頭で示した`ScratchLinearRegression`を実装していくことを目的としています。ですので、まだ実装を行っていない`__init__()`と`fit()`を実装してみましょう。\n",
    "\n",
    "最急降下法の流れに則ると、下記の流れで実装していくとよいでしょう。\n",
    "1. 学習率や学習回数の初期化＆$\\theta$の初期化を`__init__()`で行う（`no_bias`や`verbose`については、アドバンス課題のため考慮しなくても問題ないです）\n",
    "2. 推定値算出を`_linear_hypothesis`で行う\n",
    "3. `_gradient_descent`で$\\theta$を更新する\n",
    "ここで毎回損失値を保存しておくことで学習曲線を描けるので、忘れず損失値を計算し、リストで保存しておきましょう。\n",
    "4. 2,3を学習回数分繰り返す\n",
    "\n",
    "\n",
    "\n",
    "## まとめ\n",
    "- これまで作成した関数を利用して学習や値の保持を行います\n",
    "- 1~4を行うことで、最適な$theta$に更新することができます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9f3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
