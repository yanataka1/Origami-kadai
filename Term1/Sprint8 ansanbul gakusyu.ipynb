{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vrgmGB5hdnX"
   },
   "source": [
    "# Sprint8 アンサンブル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XY6tBN_Fhdnf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\n",
    "from sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み＆作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "kaVeznwdhdng",
    "outputId": "249c4853-7c47-43ef-99ca-85ba579b6346",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 読み込み\n",
    "data = pd.read_csv('train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0wuhCWmphdnh"
   },
   "outputs": [],
   "source": [
    "# 前処理（説明省略　対数変換は場合によっては不要かもしれない）\n",
    "mini_data = data[['GrLivArea','YearBuilt','SalePrice']]\n",
    "log_min_data = mini_data.apply(np.log1p)\n",
    "X = log_min_data[['GrLivArea','YearBuilt']].values\n",
    "y = log_min_data['SalePrice'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "\n",
    "ブレンディング\n",
    "バギング\n",
    "スタッキング\n",
    "\n",
    "小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。\n",
    "\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n",
    "\n",
    "train.csvを学習データ8割、検証データ2割に分割してください。\n",
    "\n",
    "\n",
    "scikit-learn\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "\n",
    "sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.svm.SVR — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "3.ブレンディング\n",
    "\n",
    "## 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "\n",
    "ブレンディングとは\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "\n",
    "手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。\n",
    "\n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。\n",
    "\n",
    "\n",
    "sklearn.ensemble.VotingClassifier — scikit-learn 0.21.3 documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n7w4I0hhdni"
   },
   "source": [
    "# 問題1\n",
    "\n",
    "単一モデルの精度出力\n",
    "\n",
    "ブレンディングモデルの精度出力\n",
    "\n",
    "2つ例を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単一モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmJyaVIphdni",
    "outputId": "6ee3f0d6-b69d-4c07-d8ce-00d3d1e7fc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名：LinearRegression()　MSE：0.062158929372223067\n",
      "モデル名：SVR()　MSE：0.05880369910471196\n",
      "モデル名：DecisionTreeRegressor()　MSE：0.08350034833340558\n"
     ]
    }
   ],
   "source": [
    "# 使用モデル一覧\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    SVR(),\n",
    "    DecisionTreeRegressor()\n",
    "]\n",
    "\n",
    "# 使用モデルでループ\n",
    "for model in models:\n",
    "    # 学習\n",
    "    model.fit(X_train,y_train)\n",
    "    # 予測\n",
    "    prediction = model.predict(X_test)\n",
    "    # MSE算出\n",
    "    mse = mean_squared_error(y_test,prediction)\n",
    "    # print('CV_MSE:',result)\n",
    "    print('モデル名：%s　MSE：%s'%(str(model),mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKaykBRphdnj"
   },
   "source": [
    "## 複数モデル（例①）\n",
    "\n",
    "別モデルを3つ学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WWvY7kGhdnj",
    "outputId": "4b836470-9820-44b9-d8a1-8bc9e742eece",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名：線形回帰/SVM/決定木　MSE：0.056741018991756854\n"
     ]
    }
   ],
   "source": [
    "# 3つのモデルを個別に学習\n",
    "model1 = LinearRegression().fit(X_train,y_train)\n",
    "model2 = SVR().fit(X_train,y_train)\n",
    "model3 = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "\n",
    "# 学習したモデルで予測\n",
    "prediction1 = model1.predict(X_test)\n",
    "prediction2 = model2.predict(X_test)\n",
    "prediction3 = model3.predict(X_test)\n",
    "\n",
    "\n",
    "# 予測値の平均値をとる\n",
    "prediction = np.mean([prediction1,prediction2,prediction3],axis=0)\n",
    "\n",
    "# MSEの算出\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "\n",
    "print('モデル名：%s　MSE：%s'%(\"線形回帰/SVM/決定木\",mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xEeLDCPhdnk"
   },
   "source": [
    "## 複数モデル（例②）\n",
    "\n",
    "同じモデルのパラメータを変えて学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2szbO99Uhdnk",
    "outputId": "c6fd6dec-74d6-4c41-cc62-f0019ae566e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名：決定木　MSE：0.060553650373665974\n"
     ]
    }
   ],
   "source": [
    "# 3つのモデルを個別に学習\n",
    "model1 = DecisionTreeRegressor(max_depth=3).fit(X_train,y_train)\n",
    "model2 = DecisionTreeRegressor(max_depth=5).fit(X_train,y_train)\n",
    "model3 = DecisionTreeRegressor(max_depth=7).fit(X_train,y_train)\n",
    "\n",
    "# 学習したモデルで予測\n",
    "prediction1 = model1.predict(X_test)\n",
    "prediction2 = model2.predict(X_test)\n",
    "prediction3 = model3.predict(X_test)\n",
    "\n",
    "\n",
    "# 予測値の平均値をとる\n",
    "prediction = np.mean([prediction1,prediction2,prediction3],axis=0)\n",
    "\n",
    "# MSEの算出\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "\n",
    "print('モデル名：%s　MSE：%s'%(\"決定木\",mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "\n",
    "バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。訓練データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "推定結果の平均をとる部分はブレンディングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "re3JKW1zhdnn"
   },
   "source": [
    "# 問題2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単一モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9X9_zUS9hdnn",
    "outputId": "1531d702-ce6f-4a8e-9258-ef8597f93f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名：決定木　MSE：0.08504807149276056\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "prediction = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "print('モデル名：%s　MSE：%s'%(\"決定木\",mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バギング（例①）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfXCkE9ohdno",
    "outputId": "59f597f1-4114-475f-dab3-0ae3909e7e40",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 何回データセットを作り直すか\n",
    "n = 20\n",
    "\n",
    "# 学習したモデルの格納\n",
    "models = []\n",
    "\n",
    "for i in range(n):\n",
    "    # 訓練データをさらにランダムに分割\n",
    "    X_bagging, _X, y_bagging, _y = train_test_split(X_train,y_train,train_size=0.2,shuffle=True)\n",
    "    # モデルの定義\n",
    "    model = DecisionTreeRegressor()\n",
    "    # 学習\n",
    "    model.fit(X_bagging,y_bagging)\n",
    "    # モデルを記録\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名：決定木　MSE：0.06006485092501557\n"
     ]
    }
   ],
   "source": [
    "# 予測値の初期値\n",
    "prediction = np.zeros(len(X_test))\n",
    "\n",
    "# 記録してあるモデルでループ\n",
    "for model in models:\n",
    "    # 予測値の算出\n",
    "    _prediction = model.predict(X_test)\n",
    "    # 予測値を加算していく\n",
    "    prediction += _prediction\n",
    "\n",
    "# 加算していった予測値をn（モデル数）で割ることで平均値を算出\n",
    "prediction = prediction/n\n",
    "\n",
    "# MSE算出\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "\n",
    "print('モデル名：%s　MSE：%s'%(\"決定木\",mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "\n",
    "スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは $K_0=3, M_0=2$ 程度にします。\n",
    "\n",
    "\n",
    "《学習時》\n",
    "\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "\n",
    "訓練データを $K_0$ 個に分割する。\n",
    "分割した内の $(K_0 - 1)$ 個をまとめて訓練データ、残り $1$ 個を推定用データとする組み合わせが $K_0$ 個作れる。\n",
    "あるモデルのインスタンスを $K_0$ 個用意し、異なる訓練データを使い学習する。\n",
    "それぞれの学習済みモデルに対して、使っていない残り $1$ 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "さらに、異なるモデルのインスタンスも $K_0$ 個用意し、同様のことを行う。モデルが $M_0$ 個あれば、 $M_0$ 個のブレンドデータが得られる。\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "\n",
    "ステージ $n-1$ のブレンドデータを$M_{n-1}$ 次元の特徴量を持つ訓練データと考え、 $K_n$ 個に分割する。以下同様である。\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "\n",
    "ステージ $N-1$ の $M_{N-1}$ 個のブレンドデータを$M_{N-1}$ 次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "《推定時》\n",
    "\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "\n",
    "テストデータを $K_0×M_0$ 個の学習済みモデルに入力し、$K_0×M_0$ 個の推定値を得る。これを $K_0$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "\n",
    "ステージ $n-1$ で得たブレンドテストを $K_n×M_n$ 個の学習済みモデルに入力し、$K_n×M_n$ 個の推定値を得る。これを $K_n$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "\n",
    "ステージ $N-1$ で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abAjL6Tlhdno"
   },
   "source": [
    "# 問題3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dZKzBvY8hdnp"
   },
   "outputs": [],
   "source": [
    "class Stacking():\n",
    "    \"\"\"スタッキング\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth, splits, models):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_depth : スタッキングの最大深さ\n",
    "        splits : データ分割数\n",
    "        models : 使用モデル一覧\n",
    "        fit_models : 学習済みモデル保存用リスト\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.n_splits = splits\n",
    "        self.models = models\n",
    "        self.fit_models = []\n",
    "        \n",
    "    def calc_blending(self,X,y,model):\n",
    "        \"\"\"ブレンドデータ生成\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        m : モデル\n",
    "        \"\"\"\n",
    "        # blendingの初期化\n",
    "        blending = np.zeros(len(X))\n",
    "        \n",
    "        # データの分割\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=False)\n",
    "        \n",
    "        # 分割されたインデックスでループ\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # データ分割\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            y_train = y_train.ravel()\n",
    "            y_test = y_test.ravel()\n",
    "            # 学習\n",
    "            model.fit(X_train, y_train)\n",
    "            # 学習済みモデルの保存\n",
    "            self.fit_models.append(model)\n",
    "            # テストデータのインデックスに予測値を格納\n",
    "            blending[test_index] = model.predict(X_test)\n",
    "            \n",
    "        return blending\n",
    "    \n",
    "    def fit(self,X,y,depth):\n",
    "        \"\"\"該当深さの学習実行\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        depth : スタッキングの「現在の」深さ\n",
    "        \"\"\"\n",
    "        # スタッキングの「現在の」深さをメンバ変数化\n",
    "        self.depth=depth\n",
    "        \n",
    "        # 最大深さまで到達していれば、その深さのモデルを学習させて処理終了\n",
    "        if self.depth == self.max_depth:\n",
    "            # 当該深さでのモデルを取得\n",
    "            self.model = self.models[self.depth]\n",
    "            # 学習\n",
    "            self.model.fit(X,y)\n",
    "            return\n",
    "        \n",
    "        # 当該深さでのモデルを取得\n",
    "        models = self.models[self.depth]\n",
    "        self.blending = np.zeros([len(X),len(models)])\n",
    "        \n",
    "        # この階層の全てのモデルで学習\n",
    "        for i,model in enumerate(models):\n",
    "            _blending = self.calc_blending(X,y,model)\n",
    "            self.blending[:,i] = _blending\n",
    "        \n",
    "        # 再帰学習\n",
    "        # コンストラクタ生成の際の引数は同じ\n",
    "        self.stk = Stacking(self.max_depth, self.n_splits, self.models)\n",
    "        \n",
    "        # 学習実行の際は、ブレンドデータを説明変数として渡す。深さも1加えてやる\n",
    "        self.stk.fit(self.blending,y,depth+1)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        y : 目的変数\n",
    "        depth : スタッキングの「現在の」深さ\n",
    "        \"\"\"\n",
    "        # 最大深さの場合は最終的な予測値を出力するのみ\n",
    "        if self.depth == self.max_depth:\n",
    "            # 予測\n",
    "            prediction = self.model.predict(X)\n",
    "            # 返す\n",
    "            return prediction\n",
    "        # 最大深さに達していない場合は、再帰的に呼び出す\n",
    "        else:\n",
    "            \n",
    "            # 予測値を0で初期化\n",
    "            self.prediction = np.zeros(len(X))\n",
    "            # 次の階層に渡すブレンドデータ(仮)の作成\n",
    "            self.blending = np.zeros([len(X),len(self.models[self.depth])])\n",
    "            # この階層の学習済みモデルでループ\n",
    "            count = 0 # 現在どのモデルを回しているか把握\n",
    "            for model in self.fit_models:\n",
    "                # 予測し、0で初期化している予測値に加算\n",
    "                self.prediction += model.predict(X)\n",
    "                # 1種類のモデル学習の終了判定\n",
    "                count+=1\n",
    "                if count%self.n_splits == 0:\n",
    "                    # 予測値を加算してきたので割って平均値を算出\n",
    "                    self.prediction = self.prediction/self.n_splits\n",
    "                    # その平均値を次の階層で使用する説明変数に格納\n",
    "                    self.blending[:,int(count/self.n_splits)-1] = self.prediction\n",
    "                    # 次の種類のモデルでの予測のため、予測値は初期化しておく\n",
    "                    self.prediction = np.zeros(len(X))\n",
    "            # 次の階層の予測関数\n",
    "            prediction = self.stk.predict(self.blending)\n",
    "            return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_yxQrsbhdnq",
    "outputId": "8fac09db-5c7a-4580-ae2a-74ceaf1d5b52",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    0:[LinearRegression(),DecisionTreeRegressor(),RandomForestRegressor()],\n",
    "    1:[ARDRegression(),SGDRegressor(),DecisionTreeRegressor()],\n",
    "    2:[HuberRegressor(),ARDRegression(),RandomForestRegressor()],\n",
    "    3:LinearRegression()\n",
    "}\n",
    "\n",
    "stk = Stacking(max_depth=3,splits=5,models=models)\n",
    "stk.fit(X_train,y_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = stk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.059\n"
     ]
    }
   ],
   "source": [
    "# Rating\n",
    "mse = mean_squared_error(y_test,prediction)\n",
    "print('MSE : {:.3f}'.format(mse))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mep_day14_ensemble_learning_en.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
