{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87785ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import *\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc04a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias=True, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.losses = np.array([]) #np.array([])でもok\n",
    "        self.losses_val = np.array([])\n",
    "        self.theta = None #スタート、ゴールになるものをinitに入れる　NoneでもOK\n",
    "        \n",
    "    # 問題6（学習と推定）\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        \"\"\"\n",
    "        # self.n_samples = X.shape[0]\n",
    "        # n_features = X.shape[1]\n",
    "\n",
    "        self.theta = np.ones((X.shape[1]+1, 1)) # 1の配列でthetaを作成。shape(X.shape[1]+1, 1)\n",
    "        one_array = np.ones((X.shape[0], 1)) # bias項サンプル数分作成\n",
    "        one_X = np.concatenate([one_array, X], axis=1) # Xとbias項を結合\n",
    "        \n",
    "        #f X_val is not None:\n",
    "        one_array = np.ones((X_val.shape[0], 1)) # bias項サンプル数分作成\n",
    "        one_X_val = np.concatenate([one_array, X_val], axis=1) # Xとbias項を結合\n",
    "\n",
    "        for i in range(self.iter):\n",
    "            # 問題1（仮定関数の計算）\n",
    "            prediction = one_X @ self.theta\n",
    "\n",
    "\n",
    "            # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "            error = prediction - y # yはy_train\n",
    "            self.theta = self.theta - (self.lr / X.shape[0]) * (error.T @ one_X).T\n",
    "            \n",
    "            # 損失計算と記録\n",
    "            prediction = one_X @ self.theta\n",
    "            loss = self.loss_func(y,prediction)\n",
    "            self.losses = np.append(self.losses, loss)\n",
    "            if X_val is not None:\n",
    "                prediction_val = one_X_val @ self.theta\n",
    "                loss_val = self.loss_func(y_val,prediction_val)\n",
    "                self.losses_val = np.append(self.losses_val, loss_val)\n",
    "\n",
    "            \n",
    "\n",
    "    # 問題1\n",
    "    def _linear_hypothesis(self, X):  # 必要に応じて引数を追加して下さい\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "        self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "          パラメータ\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "        \"\"\"\n",
    "        # X.shape(n_samples, n_features) shape[0]で行数取得,shape[1]で列数取得\n",
    "        self.n_samples = X.shape[0]  #i\n",
    "        n_features = X.shape[1]      #j\n",
    "        # Xの(n_samples, 1) のshapeの1のみの行列を作る\n",
    "        one_array = np.ones((n_samples, 1)) #bias 1\n",
    "        # Xの一列目にone_arrayを結合 \n",
    "        self.one_X = np.concatenate([one_array, X], axis=1)#[one_array, X]は　bias + ｘ\n",
    "        # one_Xの特徴量数の1のみの行列を作る(n_features+1, 1) shape[1]で列数取得\n",
    "        prediction = one_X @ self.theta #predictionはy_hat\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "    # 問題2\n",
    "    def _gradient_descent(self, X, y):\n",
    "        # _gradient_descent(self, X, y_hat, y_true, alpha= , one_X, n_samples):\n",
    "        \"\"\"\n",
    "        最急降下法によるパラメータの更新値計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        α: 学習率\n",
    "        i : サンプルのインデックス\n",
    "        j : 特徴量のインデックス\n",
    "        lr : alfa アルファ　学習率(learning rate)\n",
    "        self.coef_ : theta(coefficient) 次の形のndarray, shape (n_features,)\n",
    "        Returns\n",
    "        -------\n",
    "        theta\n",
    "        \"\"\"\n",
    "        # y_hatは　_linear_hypothesisのreturnを予定　\n",
    "        # y_trueはどこかの正解値\n",
    "        error = self.prediction - y\n",
    "        # one_Xは　Xの1列目に1のみの列を結合させてある\n",
    "        self.theta = self.theta - (self.lr / self.n_samples) * (error.T @ self.one_X).T\n",
    "\n",
    "    # 問題3\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰での推定\n",
    "        \"\"\"\n",
    "        # パラメータを決定した後、そのパラメータを用いて、予測結果を出力しなければなりません。これを推定と言います。\n",
    "        one_array = np.ones((X.shape[0], 1))\n",
    "        one_X = np.concatenate([one_array, X], axis=1)\n",
    "        prediction = one_X @ self.theta\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    # 問題4\n",
    "    def _mse(self, y,prediction):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "        \"\"\"\n",
    "        mse = ((prediction - y)**2).mean(axis=0)\n",
    "        return mse\n",
    "\n",
    "    # 問題5\n",
    "    def loss_func(self,y,prediction):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        \"\"\"\n",
    "        mse = self._mse(y,prediction)\n",
    "        loss = mse / 2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0984d",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "$h_θ(x)=θ_0x_0+θ_1x_1+...+θ_jx_j+...+θ_nx_n.(x_0=1)$\n",
    "\n",
    "x\n",
    " : 特徴量ベクトル\n",
    "\n",
    "\n",
    "θ\n",
    " : パラメータベクトル\n",
    "\n",
    "\n",
    "n\n",
    " : 特徴量の数\n",
    "\n",
    "\n",
    "x\n",
    "j\n",
    " : j番目の特徴量\n",
    "\n",
    "\n",
    "θ\n",
    "j\n",
    " : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "特徴量の数\n",
    "n\n",
    "は任意の値に対応できる実装にしてください。\n",
    "\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "$h_θ(x)=θ^T⋅x$\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945ec5c",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "$θ_j=θ_j−α\\frac{1}{m} \\sum_{i=1}^{m}[(h_θ(x^i)−y^i)x^i_j] \\quad$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$i$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$j$ : 特徴量のインデックス\n",
    "\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。\n",
    "\n",
    "#!\n",
    "[image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3338c",
   "metadata": {},
   "source": [
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "仮定関数 \n",
    "$hθ(x)$\n",
    " の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f95cd",
   "metadata": {},
   "source": [
    "## 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "$L(\\theta)=  \\frac{1 }{ m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^{2}$\n",
    "\n",
    "\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "$\n",
    "h\n",
    "_\n",
    "θ\n",
    "(\n",
    ")\n",
    "$\n",
    " : 仮定関数\n",
    "\n",
    "$\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    "$\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    "$\n",
    " : i番目のサンプルの正解値\n",
    "\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）\n",
    "\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "def MSE(y_pred, y):  \n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算  \n",
    "    Parameters  \n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)  \n",
    "      推定した値  \n",
    "    y : 次の形のndarray, shape (n_samples,)  \n",
    "      正解値  \n",
    "    Returns  \n",
    "    ----------  \n",
    "    mse : numpy.float  \n",
    "      平均二乗誤差  \n",
    "    \"\"\"  \n",
    "    pass  \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63486b8",
   "metadata": {},
   "source": [
    "## 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "目的関数（損失関数） $J(θ)$  は次の式です。\n",
    "\n",
    "$J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2$\n",
    "\n",
    "\n",
    "m\n",
    " : 入力されるデータの数\n",
    "\n",
    "$\n",
    "h\n",
    "_\n",
    "θ\n",
    "(\n",
    ")\n",
    "$\n",
    " : 仮定関数\n",
    "\n",
    "$\n",
    "x\n",
    "(\n",
    "i\n",
    ")\n",
    "$\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$\n",
    "y\n",
    "(\n",
    "i\n",
    ")\n",
    "$\n",
    " : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77de951",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f044c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1460, 1) y: (1460, 1)\n"
     ]
    }
   ],
   "source": [
    "#データセットの準備\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "X = np.array(df[['YearBuilt']])\n",
    "y = np.array(df[[\"SalePrice\"]])\n",
    "#y = y.reshape(-1)  下でyをravel関数使わない場合、ここでreshapeする。　ravel関数を適用させると、一次元のリストが返却\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd810ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xの訓練値:(1168, 1)  Yの訓練値:(1168, 1)  Xの正解値:(292, 1)  Yの正解値:(292, 1)\n"
     ]
    }
   ],
   "source": [
    "# トレーニングセットと検証セットに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=0) # ravel関数を適用させると、一次元のリストが返却\n",
    "print(f\"Xの訓練値:{X_train.shape}  Yの訓練値:{y_train.shape}  Xの正解値:{X_test.shape}  Yの正解値:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5fc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeef732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.18803167]\n",
      " [-0.29250097]\n",
      " [-1.64143071]\n",
      " ...\n",
      " [ 0.23391064]\n",
      " [ 1.05642877]\n",
      " [ 0.89192514]]\n",
      "[[-0.4570046 ]\n",
      " [-0.9834162 ]\n",
      " [-0.68730967]\n",
      " [ 0.20100991]\n",
      " [ 0.00360556]\n",
      " [-2.00333868]\n",
      " [ 1.18803167]\n",
      " [-1.1150191 ]\n",
      " [ 0.82612369]\n",
      " [ 1.08932949]\n",
      " [ 1.15513094]\n",
      " [ 0.16810919]\n",
      " [ 0.92482587]\n",
      " [-0.12799734]\n",
      " [-0.75311112]\n",
      " [-0.4570046 ]\n",
      " [ 0.69452079]\n",
      " [ 0.76032224]\n",
      " [-0.16089807]\n",
      " [-1.83883506]\n",
      " [-0.62150822]\n",
      " [ 1.08932949]\n",
      " [-0.25960024]\n",
      " [ 0.76032224]\n",
      " [ 0.10230773]\n",
      " [-2.92455899]\n",
      " [ 0.95772659]\n",
      " [-0.02929517]\n",
      " [ 1.18803167]\n",
      " [-0.78601185]\n",
      " [-0.42410387]\n",
      " [ 0.72742152]\n",
      " [ 0.23391064]\n",
      " [ 0.95772659]\n",
      " [ 1.2209324 ]\n",
      " [ 0.82612369]\n",
      " [ 1.12223022]\n",
      " [ 0.03650628]\n",
      " [ 1.05642877]\n",
      " [ 0.76032224]\n",
      " [-0.68730967]\n",
      " [-0.52280605]\n",
      " [ 1.12223022]\n",
      " [ 1.08932949]\n",
      " [ 0.79322297]\n",
      " [-0.22669952]\n",
      " [-0.52280605]\n",
      " [ 0.16810919]\n",
      " [ 0.23391064]\n",
      " [-0.81891257]\n",
      " [ 1.05642877]\n",
      " [-0.19379879]\n",
      " [ 0.20100991]\n",
      " [-0.9834162 ]\n",
      " [ 0.59581861]\n",
      " [ 0.00360556]\n",
      " [-2.00333868]\n",
      " [ 1.12223022]\n",
      " [-0.25960024]\n",
      " [-0.75311112]\n",
      " [-0.25960024]\n",
      " [-0.48990532]\n",
      " [-0.4570046 ]\n",
      " [-0.22669952]\n",
      " [ 0.76032224]\n",
      " [-0.4570046 ]\n",
      " [-0.48990532]\n",
      " [ 1.25383312]\n",
      " [-2.00333868]\n",
      " [ 1.05642877]\n",
      " [ 1.08932949]\n",
      " [-1.04921765]\n",
      " [-0.62150822]\n",
      " [ 1.18803167]\n",
      " [-0.48990532]\n",
      " [ 1.15513094]\n",
      " [-0.29250097]\n",
      " [-1.34532418]\n",
      " [ 1.12223022]\n",
      " [-0.22669952]\n",
      " [ 0.29971209]\n",
      " [ 0.23391064]\n",
      " [-2.00333868]\n",
      " [ 0.76032224]\n",
      " [-0.81891257]\n",
      " [ 1.05642877]\n",
      " [-1.83883506]\n",
      " [ 1.12223022]\n",
      " [ 1.25383312]\n",
      " [-0.42410387]\n",
      " [ 0.89192514]\n",
      " [ 0.16810919]\n",
      " [ 0.79322297]\n",
      " [ 1.02352804]\n",
      " [ 1.15513094]\n",
      " [-0.35830242]\n",
      " [ 1.08932949]\n",
      " [-1.74013288]\n",
      " [-0.02929517]\n",
      " [-1.34532418]\n",
      " [ 1.12223022]\n",
      " [ 1.05642877]\n",
      " [-0.4570046 ]\n",
      " [ 0.20100991]\n",
      " [-1.41112563]\n",
      " [ 0.66162006]\n",
      " [ 0.72742152]\n",
      " [-1.14791983]\n",
      " [ 1.12223022]\n",
      " [-1.87173578]\n",
      " [-1.90463651]\n",
      " [-0.32540169]\n",
      " [ 0.00360556]\n",
      " [-1.04921765]\n",
      " [ 0.92482587]\n",
      " [ 0.16810919]\n",
      " [ 1.05642877]\n",
      " [-0.25960024]\n",
      " [-0.09509662]\n",
      " [ 1.15513094]\n",
      " [ 1.08932949]\n",
      " [ 1.18803167]\n",
      " [-0.32540169]\n",
      " [-0.09509662]\n",
      " [ 0.92482587]\n",
      " [ 1.25383312]\n",
      " [ 1.15513094]\n",
      " [ 1.15513094]\n",
      " [ 1.15513094]\n",
      " [ 0.16810919]\n",
      " [ 0.85902442]\n",
      " [ 1.15513094]\n",
      " [ 0.26681136]\n",
      " [ 0.33261281]\n",
      " [-0.02929517]\n",
      " [ 0.89192514]\n",
      " [-1.01631693]\n",
      " [ 0.95772659]\n",
      " [-0.55570677]\n",
      " [ 0.69452079]\n",
      " [-0.68730967]\n",
      " [ 1.12223022]\n",
      " [-0.5886075 ]\n",
      " [ 0.20100991]\n",
      " [-0.06219589]\n",
      " [ 0.72742152]\n",
      " [ 1.18803167]\n",
      " [-0.39120314]\n",
      " [ 1.12223022]\n",
      " [ 0.89192514]\n",
      " [-0.22669952]\n",
      " [ 1.2209324 ]\n",
      " [ 1.18803167]\n",
      " [-2.33234594]\n",
      " [-1.5098278 ]\n",
      " [ 0.23391064]\n",
      " [-1.1150191 ]\n",
      " [-1.3782249 ]\n",
      " [ 1.18803167]\n",
      " [ 0.69452079]\n",
      " [ 0.00360556]\n",
      " [-0.39120314]\n",
      " [ 1.15513094]\n",
      " [-0.02929517]\n",
      " [ 1.15513094]\n",
      " [-1.70723216]\n",
      " [-0.25960024]\n",
      " [ 0.82612369]\n",
      " [ 1.08932949]\n",
      " [ 0.95772659]\n",
      " [-0.29250097]\n",
      " [ 0.29971209]\n",
      " [ 1.12223022]\n",
      " [ 0.53001716]\n",
      " [-0.55570677]\n",
      " [ 0.00360556]\n",
      " [-0.35830242]\n",
      " [ 0.10230773]\n",
      " [-1.54272853]\n",
      " [ 0.39841426]\n",
      " [ 0.39841426]\n",
      " [-0.09509662]\n",
      " [-1.67433143]\n",
      " [ 1.18803167]\n",
      " [-1.01631693]\n",
      " [-0.09509662]\n",
      " [-0.02929517]\n",
      " [ 1.15513094]\n",
      " [ 1.15513094]\n",
      " [ 1.08932949]\n",
      " [ 0.76032224]\n",
      " [-0.39120314]\n",
      " [ 1.08932949]\n",
      " [ 0.82612369]\n",
      " [-2.06914014]\n",
      " [ 0.43131499]\n",
      " [-0.02929517]\n",
      " [-0.42410387]\n",
      " [-0.29250097]\n",
      " [ 0.00360556]\n",
      " [-0.42410387]\n",
      " [ 0.56291789]\n",
      " [-1.01631693]\n",
      " [ 0.23391064]\n",
      " [-1.80593433]\n",
      " [-0.06219589]\n",
      " [-0.22669952]\n",
      " [ 0.95772659]\n",
      " [ 0.99062732]\n",
      " [-1.87173578]\n",
      " [ 1.08932949]\n",
      " [ 0.95772659]\n",
      " [-0.68730967]\n",
      " [-1.54272853]\n",
      " [ 0.33261281]\n",
      " [-0.19379879]\n",
      " [ 0.20100991]\n",
      " [ 0.49711644]\n",
      " [ 1.15513094]\n",
      " [ 0.03650628]\n",
      " [ 0.29971209]\n",
      " [-0.09509662]\n",
      " [-2.00333868]\n",
      " [ 0.03650628]\n",
      " [ 1.12223022]\n",
      " [ 1.05642877]\n",
      " [ 0.95772659]\n",
      " [-0.16089807]\n",
      " [-0.32540169]\n",
      " [ 0.16810919]\n",
      " [-0.7202104 ]\n",
      " [-1.14791983]\n",
      " [ 0.00360556]\n",
      " [ 0.79322297]\n",
      " [ 0.76032224]\n",
      " [-1.04921765]\n",
      " [ 0.10230773]\n",
      " [-0.55570677]\n",
      " [-0.52280605]\n",
      " [-0.35830242]\n",
      " [-0.78601185]\n",
      " [ 0.92482587]\n",
      " [ 1.02352804]\n",
      " [ 0.99062732]\n",
      " [ 0.16810919]\n",
      " [ 0.49711644]\n",
      " [ 0.43131499]\n",
      " [ 1.08932949]\n",
      " [-1.01631693]\n",
      " [ 0.92482587]\n",
      " [-0.35830242]\n",
      " [ 1.15513094]\n",
      " [-1.60852998]\n",
      " [ 1.15513094]\n",
      " [ 1.25383312]\n",
      " [ 1.08932949]\n",
      " [-0.8518133 ]\n",
      " [ 1.18803167]\n",
      " [ 1.05642877]\n",
      " [ 1.2209324 ]\n",
      " [ 0.92482587]\n",
      " [-1.01631693]\n",
      " [-0.55570677]\n",
      " [-2.33234594]\n",
      " [ 1.18803167]\n",
      " [ 1.25383312]\n",
      " [ 0.03650628]\n",
      " [-1.44402635]\n",
      " [-1.14791983]\n",
      " [ 1.2209324 ]\n",
      " [-1.5098278 ]\n",
      " [-1.47692708]\n",
      " [-1.01631693]\n",
      " [ 0.26681136]\n",
      " [-1.93753723]\n",
      " [ 1.08932949]\n",
      " [ 0.56291789]\n",
      " [-1.01631693]\n",
      " [ 1.08932949]\n",
      " [-1.67433143]\n",
      " [ 0.03650628]\n",
      " [ 1.08932949]\n",
      " [-0.95051547]\n",
      " [-0.8518133 ]\n",
      " [ 1.15513094]\n",
      " [-0.65440895]\n",
      " [ 0.03650628]\n",
      " [ 0.72742152]\n",
      " [ 1.2209324 ]\n",
      " [-1.80593433]\n",
      " [-1.01631693]\n",
      " [-1.67433143]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_std)\n",
    "print(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf2a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチ線形回帰のインスタンス化とトレーニング\n",
    "slr = ScratchLinearRegression(num_iter=5000, lr=0.005, no_bias=True ,verbose=False) #no_bias=Falseだと近似\n",
    "slr.fit(X_train_std, y_train, X_test_std, y_test)\n",
    "slr_pred_std = slr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83788ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE4980069536.6\n",
      "RMSE70569.6\n"
     ]
    }
   ],
   "source": [
    "#モデルを評価する\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(slr_pred_std, y_test)\n",
    "print('MSE{:.1f}'.format(mse))\n",
    "print('RMSE{:.1f}'.format(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347e2f1",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e68747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(16,9))\n",
    "plt.rcParams[\"font.size\"] = 20 #rcParamsは辞書形式でパラメータを扱える\n",
    "plt.scatter(range(len(slr.losses)),slr.losses,label='train_loss')\n",
    "plt.scatter(range(len(slr.losses_val)),slr.losses_val,label='val_loss')\n",
    "plt.legend()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b0bcd9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1ba69d31ed40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(slr.losses[0])\n",
    "print(slr.losses_val[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
