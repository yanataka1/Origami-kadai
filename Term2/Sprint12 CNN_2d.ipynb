{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I17rg4QtwK54"
   },
   "source": [
    "# Sprint12　畳込みニューラルネットワーク\n",
    "\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。\n",
    "\n",
    "\n",
    "データセットの用意  \n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e89fcc55b192>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train = X_train.astype(np.float)\n",
      "<ipython-input-2-e89fcc55b192>:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_test = X_test.astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(12000, 28, 28)\n",
      "(60000,)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# onehotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 訓練データと評価データに\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習に使用するその他クラスの定義\n",
    "\n",
    "これまでのsprintで定義してきたものを流用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "duKjHNocwK6C"
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Fully connected layers from number of nodes n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in subsequent layers\n",
    "    initializer : Instances of initialization methods\n",
    "    optimizer : Instances of optimization methods\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        # Initialize.\n",
    "        # Use the initializer method to initialize self.W and self.B\n",
    "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            Input\n",
    "        Returns\n",
    "        ----------\n",
    "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X,self.W) + self.B\n",
    "        \n",
    "        return self.activation.forward(self.A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            The gradient flowed in from behind.\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            forward slope\n",
    "        \"\"\"\n",
    "        dA = self.activation.backward(dZ)\n",
    "        self.dB = np.mean(dA,axis=0)\n",
    "        self.dW = np.dot(self.X.T,dA)/len(self.X)\n",
    "        dZ = np.dot(dA,self.W.T)\n",
    "        \n",
    "        # Update\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)\n",
    "    \n",
    "class HeInitializer():\n",
    "    \"\"\"\n",
    "    Initialization of weights by He\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)\n",
    "    \n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.dW\n",
    "        layer.B -= self.lr*layer.dB\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.hW = 0\n",
    "        self.hB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        self.hW += layer.dW*layer.dW\n",
    "        self.hB = layer.dB*layer.dB\n",
    "    \n",
    "        layer.W -= self.lr*layer.dW/(np.sqrt(self.hW) +1e-7)\n",
    "        layer.B -= self.lr*layer.dB/(np.sqrt(self.hB) +1e-7)\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class ReLU():\n",
    "    \"\"\"\n",
    "    Activation function : ReLU function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        self.A = A\n",
    "        return np.maximum(self.A,0)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        \n",
    "        return np.where(self.A>0,dZ,0)\n",
    "    \n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Activation Function : Softmax Function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        \n",
    "        return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)),axis=1,keepdims=True)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        return dZ\n",
    "    \n",
    "# Mini-batch processing class\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get the mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of the following form, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : ndarray of the following form, shape (n_samples, 1)\n",
    "      correct value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      Seeding random numbers in NumPy\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1] \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmW0YtuQwK6C"
   },
   "source": [
    "# 畳み込み層の重みとバイアスの初期化クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uD3iuDwMwK6D"
   },
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    \"\"\"重みとバイアスの初期化（畳込み用）\"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        --------------\n",
    "        sigma : ガウス分布の標準偏差\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, F, C, FH, FW):\n",
    "        \"\"\"重み初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        F : フィルタ数\n",
    "        C : チャンネル数\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
    "    \n",
    "    def B(self, F):\n",
    "        \"\"\"バイアス初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        F : フィルタ数\n",
    "        \"\"\"\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2fxdDrkwK6F"
   },
   "source": [
    "# 問題1　2次元畳み込み層の作成\n",
    "\n",
    "https://qiita.com/eijian/items/c947fb6b5e7a49858fb4#2-3-%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E5%B1%A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WGQfEoYwK6G"
   },
   "source": [
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります\n",
    "\n",
    "$$a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}$$\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$i$ : 配列の行方向のインデックス\n",
    "\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "\n",
    "$F_{h}, F_{w}$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "\n",
    "すべてスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "\n",
    "$w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_{m}}$ : $b_{m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ や $\\frac{\\partial L}{\\partial b_{m}}$ を求めるためのバックプロパゲーションの数式が以下である。\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "\n",
    "ただし、 $i-s<0$ または $i-s>N_{out,h}-1$ または $j-t<0$ または $j-t>N_{out,w}-1$ のとき $\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$ です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9q7iydz8wK6H"
   },
   "outputs": [],
   "source": [
    "class SimpleConv2d():\n",
    "    \"\"\"2次元畳み込みレイヤ\"\"\"\n",
    "    def __init__(self, F, C, FH, FW, P, S,\n",
    "                 initializer=None,optimizer=None,activation=None):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -------------\n",
    "        F : フィルタ数\n",
    "        C : チャンネル数\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        P : パディング数\n",
    "        S : ストライド数\n",
    "        initializer : 初期化\n",
    "        optimizer : 最適化手法\n",
    "        activation : 活性化関数\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        # 重みとバイアスの初期化\n",
    "        self.W = self.initializer.W(F,C,FH,FW)\n",
    "        self.B = self.initializer.B(F)\n",
    "        \n",
    "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
    "        \"\"\"出力サイズ計算\n",
    "        H : 入力配列の高さ\n",
    "        W : 入力配列の横幅\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        PH : パディング数（縦）\n",
    "        PW : パディング数（横）\n",
    "        SH : ストライド数（縦）\n",
    "        SW : ストライド数（横）\n",
    "        \"\"\"\n",
    "        # 高さ計算\n",
    "        OH = (H +2*PH -FH)/SH +1\n",
    "        # 横幅計算\n",
    "        OW = (W +2*PW -FW)/SW +1\n",
    "        \n",
    "        return int(OH),int(OW)\n",
    "    \n",
    "    def forward(self, X,debug=False):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ------------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        # Xをメンバ変数化\n",
    "        self.X = X\n",
    "        # 入力配列と重みの大きさ取得\n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        # 出力サイズ計算\n",
    "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
    "        # 各種サイズをメンバ変数化\n",
    "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
    "        # 返り値の初期化（これを上書きしていく）\n",
    "        A = np.zeros([N,F,OH,OW])\n",
    "        # 計算のためパディング処理\n",
    "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
    "\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ（ストライドを考慮）\n",
    "                for row in range(0,H,self.S):\n",
    "                    # 横幅でループ（ストライドを考慮）\n",
    "                    for col in range(0,W,self.S):\n",
    "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
    "                            continue\n",
    "                        # 各要素計算\n",
    "                        A[n,ch,row,col] = \\\n",
    "                        np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "                               *self.W[ch,:,:,:]) +self.B[ch]\n",
    "        # 活性化関数に通して返す\n",
    "        if debug==True:\n",
    "            return A\n",
    "        else:\n",
    "            return  self.activation.forward(A)\n",
    "    \n",
    "    def backward(self, dZ,debug=False):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        dZ : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        # 活性化関数の逆伝播処理\n",
    "        if debug==True:\n",
    "            dA = dZ\n",
    "        else:\n",
    "            dA = self.activation.backward(dZ)\n",
    "        # 順伝播の際にメンバ変数化しておいた各種サイズを取得\n",
    "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
    "        # 返り値と重みとバイアスの初期化（これを上書きしていく）\n",
    "        dZ = np.zeros(self.X_pad.shape) # X_padのサイズで初期化していることに注意\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "        \n",
    "        # dZ（逆伝播）\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ（ストライドを考慮）\n",
    "                for row in range(0,H,self.S):\n",
    "                    # 横幅でループ（ストライドを考慮）\n",
    "                    for col in range(0,W,self.S):\n",
    "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
    "                            continue\n",
    "                        # 各要素計算\n",
    "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
    "        \n",
    "        # X_padのサイズになっているので、不要な部分を削除\n",
    "        if self.P == 0:\n",
    "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
    "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
    "        else:\n",
    "            dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
    "            dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
    "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "            dZ = np.delete(dZ,dl_cols,axis=3)\n",
    " \n",
    "        # dW（重み）\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ\n",
    "                for row in range(OH):\n",
    "                    # 横幅でループ\n",
    "                    for col in range(OW):\n",
    "                        # 各要素計算\n",
    "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "        \n",
    "        # dB（バイアス）\n",
    "        # フィルター数でループ\n",
    "        for ch in range(F):\n",
    "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "        \n",
    "        # 重み更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2　小さな配列での2次元畳み込み層の実験\n",
    "\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力 x、重み w を次のようにします。\n",
    "\n",
    " CNN2 のフォワードを流す時の入力データ  \n",
    " (1,1,4,4)  \n",
    "x = np.array([[[[ 1,  2,  3,  4],  \n",
    "                [ 5,  6,  7,  8],  \n",
    "                [ 9, 10, 11, 12],  \n",
    "                [13, 14, 15, 16]]]])  \n",
    " (2,3,3)  \n",
    "w = np.array([[[ 0.,  0.,  0.],  \n",
    "               [ 0.,  1.,  0.],  \n",
    "               [ 0., -1.,  0.]],  \n",
    "              [[ 0.,  0.,  0.],  \n",
    "               [ 0., -1.,  1.],  \n",
    "               [ 0.,  0.,  0.]]])  \n",
    "               \n",
    "ワードプロパゲーションをすると出力は次のようになります。\n",
    "\n",
    "array([[[-4, -4],  \n",
    "        [-4, -4]],  \n",
    "       [[ 1,  1],  \n",
    "        [ 1,  1]]])  \n",
    "        \n",
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。\n",
    "\n",
    " (?,1,2,2,)  \n",
    "delta = np.array([[[ -4,  -4],  \n",
    "                   [ 10,  11]],  \n",
    "                  [[  1,  -7],  \n",
    "                   [  1, -11]]])  \n",
    "\n",
    "バックプロパゲーションをすると次のような値になります。パディングがある場合は出力は次のようになります。\n",
    "\n",
    "array([[-5,  4],  \n",
    "       [13, 27]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-4. -4.]\n",
      "   [-4. -4.]]\n",
      "\n",
      "  [[ 1.  1.]\n",
      "   [ 1.  1.]]]]\n",
      "[[[[-5.  4.]\n",
      "   [13. 27.]]]]\n"
     ]
    }
   ],
   "source": [
    "# データの定義\n",
    "x = np.array([[[[ 1,  2,  3,  4],[ 5,  6,  7,  8],[ 9, 10, 11, 12],[13, 14, 15, 16]]]])\n",
    "w = np.array([[[[ 0.,  0.,  0.],[ 0.,  1.,  0.],[ 0., -1.,  0.]]],[[[ 0.,  0.,  0.],[ 0., -1.,  1.],[ 0.,  0.,  0.]]]])\n",
    "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
    "\n",
    "# インスタンス定義と重み上書き\n",
    "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU())\n",
    "simple_conv_2d.W = w\n",
    "\n",
    "# 順伝播\n",
    "A = simple_conv_2d.forward(x,True)\n",
    "print(A)\n",
    "\n",
    "# 逆伝播\n",
    "dZ = simple_conv_2d.backward(da,True)\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnistを使ったテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 28, 28)\n",
      "(5, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# ストライド/パディング/バッチ数の定義\n",
    "S = 1\n",
    "P = 1\n",
    "N = 5 \n",
    "\n",
    "# 入力配列と重みのサイズ定義\n",
    "N,C,H,W = (5,1,28,28)\n",
    "F,C,FH,FW = (4,1,3,3)\n",
    "\n",
    "# X（入力配列生成）\n",
    "X_sample = X_train[0:N].reshape(N,C,H,W)\n",
    "\n",
    "# インスタンス生成\n",
    "simple_conv_2d = SimpleConv2d(F=F, C=C, FH=FH, FW=FW, P=P, S=S,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU())\n",
    "\n",
    "# 順伝播\n",
    "A = simple_conv_2d.forward(X_sample)\n",
    "print(A.shape)\n",
    "\n",
    "# 逆伝播\n",
    "dA = np.ones(A.shape)\n",
    "dZ = simple_conv_2d.backward(X_sample)\n",
    "print(dZ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hwp3fknwK6H"
   },
   "source": [
    "# 問題3　2次元畳み込み後の出力サイズ\n",
    "\n",
    "問題2のクラス内で定義済み\n",
    "\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "\n",
    "$h$ が高さ方向、 $w$ が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3_fksagCwK6I",
    "outputId": "63ff990b-c074-4ee5-e55f-441fcfd08b1e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VkJ-KlgwK6J"
   },
   "source": [
    "# 問題4　最大プーリング層の作成\n",
    "\n",
    "https://qiita.com/eijian/items/c947fb6b5e7a49858fb4#2-2-%E3%83%97%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E5%B1%A4\n",
    "\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "$a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}$\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_{h}×S_{w}$ の範囲内の行（p）と列（q）\n",
    "\n",
    "\n",
    "$S_{h}, S_{w}$ : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス $(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ViTwMwPvwK6J"
   },
   "outputs": [],
   "source": [
    "class MaxPool2D():\n",
    "    \"\"\"最大プーリング層\n",
    "    \"\"\"\n",
    "    def __init__(self,P):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -----------\n",
    "        P : プーリング幅\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        # 順伝播の返り値\n",
    "        self.PA = None\n",
    "        # 最大値のインデックス記録\n",
    "        self.Pindex = None\n",
    "        \n",
    "    def forward(self,A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        A : 入力配列\n",
    "        \"\"\"\n",
    "        # 入力配列のサイズ\n",
    "        N,F,OH,OW = A.shape\n",
    "        # \n",
    "        PS = self.P\n",
    "        # 縦軸と横軸のスライド回数\n",
    "        PH,PW = int(OH/PS),int(OW/PS)\n",
    "        \n",
    "        # 各種パラメータの保存\n",
    "        self.params = N,F,OH,OW,PS,PH,PW\n",
    "        \n",
    "        # プーリング処理のための初期化\n",
    "        self.PA = np.zeros([N,F,PH,PW])\n",
    "        self.Pindex = np.zeros([N,F,PH,PW])\n",
    "        \n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 縦方向スライド回数\n",
    "                for row in range(PH):\n",
    "                    # 横方向スライド回数\n",
    "                    for col in range(PW):\n",
    "                        # 順伝播の値計算\n",
    "                        self.PA[n,ch,row,col] = \\\n",
    "                        np.max(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        # 最大値のインデックス記録\n",
    "                        self.Pindex[n,ch,row,col] = \\\n",
    "                        np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \"\"\"逆伝播の値\n",
    "        Parameters\n",
    "        -----------\n",
    "        dA : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        # 保存しておいた各種パラメータ取得\n",
    "        N,F,OH,OW,PS,PH,PW = self.params\n",
    "        # 逆伝播の値\n",
    "        dP = np.zeros([N,F,OH,OW])\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 縦方向スライド回数\n",
    "                for row in range(PH):\n",
    "                    # 横方向スライド回数\n",
    "                    for col in range(PW):\n",
    "                        # 最大値を取得してきたインデックスの取得\n",
    "                        idx = self.Pindex[n,ch,row,col]\n",
    "                        # 逆伝播の一時保存変数\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            # 該当インデックスはその値\n",
    "                            if i == idx:\n",
    "                                tmp[i] = dA[n,ch,row,col]\n",
    "                            # それ以外は0\n",
    "                            else:\n",
    "                                tmp[i] = 0\n",
    "                        # 返り値の該当場所に格納\n",
    "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
    "        \n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_K85cvI6wK6J",
    "outputId": "9725b784-ad28-44a2-8be3-aa1fe3688e87",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------X\n",
      "[[[[6 1 3 5 1 7]\n",
      "   [5 1 0 8 0 8]\n",
      "   [6 2 1 2 1 8]\n",
      "   [6 1 3 4 4 4]\n",
      "   [7 6 8 6 5 1]\n",
      "   [3 6 6 4 4 2]]]]\n",
      "---------------A\n",
      "[[[[6. 8. 8.]\n",
      "   [6. 4. 8.]\n",
      "   [7. 8. 5.]]]]\n",
      "---------------dA\n",
      "[[[[2 5 4]\n",
      "   [6 7 5]\n",
      "   [6 7 5]]]]\n",
      "---------------dZ\n",
      "[[[[2. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 5. 0. 4.]\n",
      "   [6. 0. 0. 0. 0. 5.]\n",
      "   [0. 0. 0. 7. 0. 0.]\n",
      "   [6. 0. 7. 0. 5. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "# データ準備\n",
    "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
    "print(\"---------------X\")\n",
    "print(X)\n",
    "\n",
    "# インスタンス生成と順伝播\n",
    "Pooling = MaxPool2D(P=2)\n",
    "A = Pooling.forward(X)\n",
    "print(\"---------------A\")\n",
    "print(A)\n",
    "\n",
    "# 逆伝播してきた配列定義\n",
    "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
    "print(\"---------------dA\")\n",
    "print(dA)\n",
    "\n",
    "# 逆伝播\n",
    "dZ = Pooling.backward(dA)\n",
    "print(\"---------------dZ\")\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdMUr2VLwK6M"
   },
   "source": [
    "# 問題6　平滑化\n",
    "\n",
    "最終的な出力を1次元配列とするため、平滑化レイヤーを作成する。\n",
    "\n",
    "why:分類にしろ回帰にしろ、2次元のままじゃ扱えない\n",
    "\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CGFt2uxFwK6M"
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"平滑化レイヤー\"\"\"\n",
    "    def __ini__(self):\n",
    "        \"\"\"コンストラクタ\"\"\"\n",
    "        pass\n",
    "    def forward(self,X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X),-1)\n",
    "\n",
    "    def backward(self,X):\n",
    "        \"\"\"逆伝播の値\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        return X.reshape(self.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0uJcS2MHwK6M",
    "outputId": "32f159e4-54ac-4100-f256-57f97724f422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_shape: (20, 50)\n",
      "Backward_shape: (20, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "# データ準備\n",
    "TEST = np.zeros([20,2,5,5])\n",
    "\n",
    "# インスタンス生成\n",
    "flt = Flatten()\n",
    "\n",
    "# 順伝播\n",
    "flat_forward = flt.forward(TEST)\n",
    "\n",
    "# 逆伝播\n",
    "flat_back = flt.backward(flat_forward)\n",
    "\n",
    "print('Forward_shape:',flat_forward.shape)\n",
    "print('Backward_shape:',flat_back.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fux5jvxuwK6N"
   },
   "source": [
    "# 問題7　学習と推定\n",
    "\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hnkAOmCEwK6N"
   },
   "outputs": [],
   "source": [
    "# Scratch CNN\n",
    "class Scratch2dCNNClassifier():\n",
    "    \"\"\"CNNスクラッチ\n",
    "    \"\"\"\n",
    "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -----------\n",
    "        NN : 辞書型でレイヤーのインスタンスを格納\n",
    "        CNN : 辞書型でレイヤーのインスタンスを格納\n",
    "        n_epoch : 学習回数\n",
    "        n_batch : バッチ数\n",
    "        verbose : ログ出力するか否か\n",
    "        \"\"\"\n",
    "        self.NN = NN\n",
    "        self.CNN = CNN\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        # ログ記録用\n",
    "        self.log_loss = np.zeros(self.n_epoch)\n",
    "        self.log_acc = np.zeros(self.n_epoch)\n",
    "        \n",
    "        \n",
    "    def loss_function(self,y,yt):\n",
    "        \"\"\"クロスエントロピー誤差\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 予測値\n",
    "        yt : 正解データ\n",
    "        \"\"\"\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    def accuracy(self,Z,Y):\n",
    "        \"\"\"クロスエントロピー誤差\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 予測値\n",
    "        Y : 正解データ\n",
    "        \"\"\"\n",
    "        return accuracy_score(Y,Z)\n",
    "                \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"\n",
    "        # 学習回数分ループ\n",
    "        for epoch in range(self.n_epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            # バッチの合計損失格納\n",
    "            self.loss = 0\n",
    "            # ミニバッチイテレータでループ\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:              \n",
    "                ############### 順伝播\n",
    "                # データ準備\n",
    "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
    "                # 畳込み\n",
    "                for layer in range(len(self.CNN)):\n",
    "                    forward_data = self.CNN[layer].forward(forward_data)\n",
    "                # 平滑化\n",
    "                flt = Flatten()\n",
    "                forward_data = flt.forward(forward_data)\n",
    "                # 通常のNN\n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                    \n",
    "                ############### 逆伝播\n",
    "                # データ準備\n",
    "                Z = forward_data\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                # 通常のNN\n",
    "                for layer in range(len(self.NN)-1,-1,-1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                # 平滑化\n",
    "                backward_data = flt.backward(backward_data)\n",
    "                # 畳み込み\n",
    "                for layer in range(len(self.CNN)-1,-1,-1):\n",
    "                    backward_data = self.CNN[layer].backward(backward_data)\n",
    "                \n",
    "                # 損失計算\n",
    "                self.loss += self.loss_function(Z,mini_y_train)\n",
    "                if self.verbose:\n",
    "                    print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
    "            # 損失記録用\n",
    "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
    "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # データ準備\n",
    "        pred_data = X[:,np.newaxis,:,:]\n",
    "        \n",
    "        # 畳込み\n",
    "        for layer in range(len(self.CNN)):\n",
    "            pred_data = self.CNN[layer].forward(pred_data)\n",
    "        # 平滑化\n",
    "        pred_data = flt.forward(pred_data)\n",
    "        # 通常のNN\n",
    "        for layer in range(len(self.NN)):\n",
    "            pred_data = self.NN[layer].forward(pred_data)\n",
    "        # 最も大きい値のインデックスを採用\n",
    "        return np.argmax(pred_data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Nd2itkg0wK6N"
   },
   "outputs": [],
   "source": [
    "# レイヤー群定義\n",
    "NN = {\n",
    "    0:FC(1960, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "    1:FC(200, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "    2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
    "}\n",
    "\n",
    "CNN = {\n",
    "    0:SimpleConv2d(\n",
    "        F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
    "        initializer=SimpleInitializerConv2d(),\n",
    "        optimizer=SGD(),\n",
    "        activation=ReLU()),\n",
    "    1:MaxPool2D(2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "at4_QFo8wK6O"
   },
   "outputs": [],
   "source": [
    "# CNNクラスのインスタンス化\n",
    "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=1,n_batch=20,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fc43dcc63245>:242: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.031114\n",
      "batch loss 0.040685\n",
      "batch loss 0.042692\n",
      "batch loss 0.028742\n",
      "batch loss 0.037760\n",
      "0.036198544929930895 0.93\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "cnn1.fit(X_train[0:100],y_train_one_hot[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ou7d7r_BwK6O",
    "outputId": "ce01563d-16df-4914-a9bc-eb321c6f15b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.860\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "y_pred = cnn1.predict(X_val[0:100])\n",
    "\n",
    "# ACC算出\n",
    "accuracy = accuracy_score(np.argmax(y_val[0:100],axis=1), y_pred)\n",
    "print('accuracy:{:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9QTh7iR_wK6O",
    "outputId": "d201b5c1-80ea-402c-a760-4db5f671a5c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の可視化\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "fig=plt.subplots(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('LOSS')\n",
    "plt.plot(cnn1.log_loss,'bo--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('ACC')\n",
    "plt.plot(cnn1.log_acc,'rs--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtP8R-9hwK6Q"
   },
   "source": [
    "# 問題10　出力サイズとパラメータ数の計算\n",
    "\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    "1.\n",
    "\n",
    "* 入力サイズ : 144×144, 3チャンネル\n",
    "* フィルタサイズ : 3×3, 6チャンネル\n",
    "* ストライド : 1\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：6×142×142\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：162\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：6\n",
    "\n",
    "2.\n",
    "\n",
    "* 入力サイズ : 60×60, 24チャンネル\n",
    "* フィルタサイズ : 3×3, 48チャンネル\n",
    "* ストライド　: 1\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：48×58×58\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：10368\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：48\n",
    "\n",
    "3.\n",
    "\n",
    "* 入力サイズ : 20×20, 10チャンネル\n",
    "* フィルタサイズ: 3×3, 20チャンネル\n",
    "* ストライド : 2\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：20x9x9\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：1800\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：20\n",
    "\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "mep_day19_CNN2_en.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
