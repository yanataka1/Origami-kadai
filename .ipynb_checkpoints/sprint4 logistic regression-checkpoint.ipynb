{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f6b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジステック回帰\n",
    "\n",
    "class ScratchLogisticRegression():\n",
    "    \"\"\"\n",
    "    ロジスティック回帰のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使い確率を推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bde322",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "ロジスティック回帰の仮定関数のメソッドをScratchLogisticRegressionクラスに実装してください。\n",
    "\n",
    "\n",
    "ロジスティック回帰の仮定関数は、線形回帰の仮定関数を シグモイド関数 に通したものです。シグモイド関数は以下の式で表されます。\n",
    "\n",
    "\n",
    "### $g(z) = \\frac{1}{1+e^{−z}}$\n",
    "\n",
    "線形回帰の仮定関数は次の式でした。\n",
    "\n",
    "### $h_\\theta(x) = \\theta^T \\cdot x$\n",
    "\n",
    "まとめて書くと、ロジスティック回帰の仮定関数は次のようになります。\n",
    "\n",
    "### $h_\\theta(x) = \\frac{1}{1+e^{−\\theta^T \\cdot x}}$\n",
    "\n",
    "$x$ : 特徴量ベクトル\n",
    "\n",
    "\n",
    "$\\theta$ : パラメータ（重み）ベクトル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869179e7",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください。\n",
    "\n",
    "\n",
    "\n",
    "### $\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)}  ,j = 0\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\biggl(\\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)} \\biggr) + \\frac{λ}{m}\\theta_j　 ,j\\geq 1$\n",
    "\n",
    "\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$i$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$j$ : 特徴量のインデックス\n",
    "\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x$ : 特徴量ベクトル\n",
    "\n",
    "\n",
    "$\\theta$ : パラメータ（重み）ベクトル\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解ラベル\n",
    "\n",
    "\n",
    "$\\theta_j$ : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "$λ$ : 正則化パラメータ\n",
    "\n",
    "\n",
    "以上の式には正則化項が含まれます。正則化項は過学習を防ぐ目的で用いられます。切片である$\\theta_0$が正則化項に含まれていないのは、切片を除いた、特徴量に対する係数を同じ視点で議論することができるようにするためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c89eb",
   "metadata": {},
   "source": [
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLogisticRegressionクラスの雛形に含まれるpredictメソッドとpredict_probaメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "仮定関数 $h_\\theta(x)$ の出力がpredict_probaの戻り値、さらにその値に閾値を設けて1と0のラベルとしたものがpredictの戻り値となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd9a90",
   "metadata": {},
   "source": [
    "##【問題4】目的関数\n",
    "以下の数式で表されるロジスティック回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "なお、この数式には正則化項が含まれています。\n",
    "\n",
    "\n",
    "＊数式が見切れる場合、DIVERを全画面にして御覧ください。\n",
    "\n",
    "### $J(\\theta)=  \\frac{1}{m}  \\sum_{i=1}^{m}[−y^{(i)} log(h_θ(x^{(i)})) − (1−y^{(i)}) log(1−h_θ(x^{(i)}))] +\\frac{λ}{2m}\\sum_{j=1}^nθ^2_j$ \n",
    "\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "\n",
    "\n",
    "$h_\\theta()$ : 仮定関数\n",
    "\n",
    "\n",
    "$x$ : 特徴量ベクトル\n",
    "\n",
    "\n",
    "$\\theta$ : パラメータ（重み）ベクトル\n",
    "\n",
    "\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解ラベル\n",
    "\n",
    "\n",
    "$\\theta_j$ : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "$n$ : 特徴量の数\n",
    "\n",
    "\n",
    "$λ$ : 正則化パラメータ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4e10b",
   "metadata": {},
   "source": [
    "## 【問題5】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したirisデータセットのvirgicolorとvirginicaの2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "\n",
    "\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e338537",
   "metadata": {},
   "source": [
    "## 【問題6】学習曲線のプロット\n",
    "学習曲線を見て損失が適切に下がっているかどうか確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a168a",
   "metadata": {},
   "source": [
    "## 【問題7】決定領域の可視化\n",
    "決定領域を可視化してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
