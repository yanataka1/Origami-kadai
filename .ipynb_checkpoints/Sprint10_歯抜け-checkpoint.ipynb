{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 10　ディープニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データ→行データ\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 分割(訓練データ・評価データ\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# one-hotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1 全結合層のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"全結合層\"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        initializer : 初期化インスタンス\n",
    "        optimizer : 勾配更新手法\n",
    "        \"\"\"\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        # 初期化インスタンスの関数実行\n",
    "        self.W = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        self.B = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        # 最適化インスタンス\n",
    "        self.optimizer = optimizer\n",
    "        # 勾配更新の際に使用（AdaGradのみ）\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        # 逆伝播時に使用\n",
    "        self.Z = X\n",
    "        # 順伝播計算部分本体\n",
    "        self.A = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 前の層から逆伝播してきた値（活性化関数の逆伝播の値が入ってくる）\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        前回のSprint9 ニューラルネットワークでは下記のような逆伝播処理になっていた\n",
    "            0 ## 2層目\n",
    "            1 dZ2 = dA3 @ self.W3.T\n",
    "            2 dA2 = dZ2 * (1 - self.tanh_function(self.A2)**2)\n",
    "            3 dW2 = self.Z1.T @ dA2\n",
    "            4 dB2 = np.sum(dA2, axis=0)\n",
    "            5 ## 1層目\n",
    "            6 dZ1 = dA2 @ self.W2.T\n",
    "            7 dA1 = dZ1 * (1 - self.tanh_function(self.A1)**2)\n",
    "            8 dW1 = X.T @ dA1\n",
    "            9 dB1 = np.sum(dA1, axis=0)\n",
    "        勾配の計算\n",
    "            ここでは、活性化関数の逆伝播は別で実装し、その値をこの関数の引数として受け取っているので、\n",
    "            この関数の  dA  は、Sprint9の上記の  dA2  に該当する\n",
    "            よって、上記3,4に該当する処理を書いていけばいい\n",
    "        逆伝播の値の計算\n",
    "            活性化関数の逆伝播に渡してやる値、つまりSprint9の上記の  dZ1  に該当する\n",
    "        重み更新\n",
    "            勾配dB,dWが計算されているので、このインスタンス自身をoptimizerインスタンスのupdate関数に渡してやる\n",
    "            optimizerインスタンスのupdate関数の引数は、layerとなっているので、update関数内では、layer.変数名で\n",
    "            このインスタンスの各種メンバ変数にアクセスできる\n",
    "        \"\"\"\n",
    "        # バイアス項の勾配\n",
    "        self.dB = np.sum(XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX, axis=0)\n",
    "        # バイアス項以外の勾配\n",
    "        self.dW = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        # 逆伝播させる値\n",
    "        self.dZ = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        # 重み更新\n",
    "        self = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2　初期化方法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"各種重みの初期化\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 重みの初期化の際のガウス分布の標準偏差\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題3　最適化手法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"勾配更新手法\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : FCクラスのインスタンス\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        FCクラス内のbackward関数内で下記の要に実行されている\n",
    "            0 self.optimizer.update(self)\n",
    "        引数に「FCクラスのインスタンス自身」が入っていることを考えると\n",
    "        layer.dW , layer.dB , layer.Z は「FCクラスのインスタンスのメンバ変数」にアクセスしていると考えられる\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4　活性化関数のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \"\"\"シグモイド関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \"\"\"tanh関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\"Softmax関数\"\"\"\n",
    "    def forward(self, A): \n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 出力値\n",
    "        y : 正解データ\n",
    "        \"\"\"\n",
    "        # 逆伝播の値\n",
    "        dA = Z - y\n",
    "        # 損失\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5　ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"ReLU関数\"\"\"\n",
    "    def forward(self, A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 順伝播されてきた値\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        dZ : 逆伝播されてきた値\n",
    "        \"\"\"\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題6　重みの初期値\n",
    "\n",
    "全体の構造としては、`SimpleInitializer`と同じで、W,B関数で、それぞれ初期化された重みを返してやっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"Xavierの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : 使用されていない\n",
    "        \n",
    "        Overview\n",
    "        ----------\n",
    "        なぜ使用されていないのに、引数として受け取っているのか\n",
    "        \n",
    "        初期化クラスは、概略すると、下記のように使用されている\n",
    "        \n",
    "        呼び出しの大元\n",
    "            dnn = ScratchDeepNeuralNetrowkClassifier(initializer=SGD or XavierInitializer or HeInitializer) \n",
    "            \n",
    "        定義部分(ScratchDeepNeuralNetrowkClassifier)\n",
    "            class ScratchDeepNeuralNetrowkClassifier:\n",
    "                def __init__(self,xxx,xxx,xxx,initializer):\n",
    "                    .....\n",
    "                    self.initializer = initializer\n",
    "                    .....\n",
    "                def fit(self,xxx,xxx,xxx):\n",
    "                    self.initializer(self.sigma)\n",
    "        \n",
    "        つまり、\n",
    "        「呼び出しの大元」で、どの初期化クラスが渡されるかわからないので、\n",
    "        初期化クラスによっては、sigmaが必要なものと、別途計算が必要なものがあるので、\n",
    "        同じ呼び出し方をしてやるために、この初期かクラスのコンストラクタでも引数として、sigmaを受け取っている\n",
    "        \n",
    "        同じ呼び出し方をしてやらないのであれば、上記fitは、下記のような書き方でも可能\n",
    "            if initializerのクラス名 == \"SGD\":\n",
    "                self.initializer(self.sigma)\n",
    "            else initializerのクラス名 != \"SGD\":\n",
    "                self.initializer()\n",
    "        \"\"\"\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "        \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"Heの初期化クラス\"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : 前の層のノード数\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        self.sigma = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : 当該層のノード数\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題7　最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"最適化手法（AdaGrad）\"\"\"\n",
    "    def __init__(self, lr):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : 学習率\n",
    "        \"\"\"\n",
    "        self.lr = lr \n",
    "    \n",
    "    def update(self, layer):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : layerインスタンス\n",
    "        \"\"\"\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 # 0割エラー防止のため\n",
    "        layer.W -= self.lr * layer.dW / (XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX) / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題8　クラスの完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        \"\"\"通常のコンストラクタと同様の働き\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数（画像の1次元データ）\n",
    "        y : 目的変数（ラベル）\n",
    "        batch_size : 必要なミニバッチのデータ数\n",
    "        seed : ランダムシード固定\n",
    "        \"\"\"\n",
    "        # ランダムシードの固定（学習ごとに同じ生成順）\n",
    "        np.random.seed(seed)\n",
    "        # バッチ数のメンバ変数\n",
    "        self.batch_size = batch_size\n",
    "        # データ全体の長さ分のインデックスをランダムに並べ替え\n",
    "        # np.random.permutation:配列をランダムに並べ替え\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        # 並べ替えたインデックスと同じ順番で説明変数と目的変数を並べ替え\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        # データ数をバッチ数で割って、何回呼び出せば、全データを学習したことになるかの判定\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # 何回目の呼び出しか\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # 全データを学習すればストップ\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        # 並び変えた_X,_yの何番目のインデックスを採用するか\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        # returnする前にカウンタに+1しておく\n",
    "        self._counter += 1\n",
    "        # 説明変数と目的変数を返す\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,batch_size=20,n_features=784,n_nodes1 =400,n_nodes2 = 200,n_output =10,lr =0.005,epoch=10,sigma=0.02,optimizer=SGD, initializer=HeInitializer,activater=ReLU,output_activater=Softmax,verbose=True):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : バッチサイズ（default:20)\n",
    "        n_features : 説明変数の数（default:784)\n",
    "        n_nodes1 : 前の層のノード数（default:400)\n",
    "        n_nodes2 : 当該層のノード数（default:200)\n",
    "        n_output : 出力層のノード数（default:10)\n",
    "        sigma : 初期化時のパラメータ（default:0.02)\n",
    "        lr : 学習率（default:0.005)\n",
    "        verbose : 計算過程の出力（default:True)\n",
    "        epoch : 学習回数（default:10)\n",
    "        optimizer : 最適化手法（default:SGD)\n",
    "        initializer : 初期化方法（default:HeInitializer）\n",
    "        activater : 活性化関数（default:ReLU）\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features \n",
    "        self.n_nodes1 = n_nodes1  \n",
    "        self.n_nodes2 = n_nodes2 \n",
    "        self.n_output = n_output\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = optimizer \n",
    "        self.sigma = sigma\n",
    "        self.initializer = initializer \n",
    "        self.activater = activater\n",
    "        self.output_activater = output_activater \n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"\n",
    "        # lossの記録用配列\n",
    "        self.loss_train = [] \n",
    "        self.loss_val = [] \n",
    "        # 最適化手法の初期化\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        # 各層の初期化\n",
    "        self.FC1 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        self.activation1 = self.activater()\n",
    "        self.FC2 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        self.activation2 = self.activater()\n",
    "        self.FC3 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "        self.activation3 = self.output_activater()\n",
    "        \n",
    "        # 学習回数分ループ\n",
    "        for i in range(self.epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            # ミニバッチイテレータループ\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "                Z1 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                ## 逆伝播\n",
    "                dA3, loss = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "                dZ2 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "                dA2 = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) \n",
    "                \n",
    "            # 過程出力\n",
    "            if self.verbose:\n",
    "                ## 順伝播\n",
    "                # 1層目\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                # 2層目\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                # 3層目\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)      \n",
    "                # 損失計算と記録\n",
    "                loss = self.activation3.backward(Z3, y)[1]\n",
    "                self.loss_train.append(loss)\n",
    "                print('epoch:%d train_loss:%f'%(i,loss))\n",
    "                # 評価データ見る\n",
    "                if X_val is not None:\n",
    "                    ## 順伝播\n",
    "                    # 1層目\n",
    "                    A1 = self.FC1.forward(X_val)\n",
    "                    Z1 = self.activation1.forward(A1)\n",
    "                    # 2層目\n",
    "                    A2 = self.FC2.forward(Z1)\n",
    "                    Z2 = self.activation2.forward(A2)\n",
    "                    # 3層目\n",
    "                    A3 = self.FC3.forward(Z2)\n",
    "                    Z3 = self.activation3.forward(A3)\n",
    "                    # 損失計算と記録\n",
    "                    self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        ## 順伝播\n",
    "        # 1層目\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        # 2層目\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        # 3層目\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        # 最も大きいインデックスを採用\n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題9　学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:1.341763\n",
      "epoch:1 train_loss:0.839142\n",
      "epoch:2 train_loss:0.631474\n",
      "epoch:3 train_loss:0.527555\n",
      "epoch:4 train_loss:0.462877\n",
      "epoch:5 train_loss:0.420593\n",
      "epoch:6 train_loss:0.384168\n",
      "epoch:7 train_loss:0.359303\n",
      "epoch:8 train_loss:0.339498\n",
      "epoch:9 train_loss:0.322449\n",
      "epoch:10 train_loss:0.305921\n",
      "epoch:11 train_loss:0.294734\n",
      "epoch:12 train_loss:0.281875\n",
      "epoch:13 train_loss:0.271151\n",
      "epoch:14 train_loss:0.261995\n",
      "epoch:15 train_loss:0.253288\n",
      "epoch:16 train_loss:0.243322\n",
      "epoch:17 train_loss:0.234948\n",
      "epoch:18 train_loss:0.226525\n",
      "epoch:19 train_loss:0.219443\n",
      "epoch:20 train_loss:0.213260\n",
      "epoch:21 train_loss:0.206950\n",
      "epoch:22 train_loss:0.198879\n",
      "epoch:23 train_loss:0.193724\n",
      "epoch:24 train_loss:0.186935\n",
      "epoch:25 train_loss:0.183388\n",
      "epoch:26 train_loss:0.177493\n",
      "epoch:27 train_loss:0.173744\n",
      "epoch:28 train_loss:0.168659\n",
      "epoch:29 train_loss:0.162357\n",
      "epoch:30 train_loss:0.158473\n",
      "epoch:31 train_loss:0.155210\n",
      "epoch:32 train_loss:0.150173\n",
      "epoch:33 train_loss:0.147048\n",
      "epoch:34 train_loss:0.141134\n",
      "epoch:35 train_loss:0.137804\n",
      "epoch:36 train_loss:0.134250\n",
      "epoch:37 train_loss:0.130143\n",
      "epoch:38 train_loss:0.128144\n",
      "epoch:39 train_loss:0.123264\n",
      "epoch:40 train_loss:0.121383\n",
      "epoch:41 train_loss:0.118450\n",
      "epoch:42 train_loss:0.114503\n",
      "epoch:43 train_loss:0.111151\n",
      "epoch:44 train_loss:0.108046\n",
      "epoch:45 train_loss:0.106223\n",
      "epoch:46 train_loss:0.104019\n",
      "epoch:47 train_loss:0.100672\n",
      "epoch:48 train_loss:0.096692\n",
      "epoch:49 train_loss:0.095372\n",
      "epoch:50 train_loss:0.092302\n",
      "epoch:51 train_loss:0.092203\n",
      "epoch:52 train_loss:0.087313\n",
      "epoch:53 train_loss:0.086351\n",
      "epoch:54 train_loss:0.083195\n",
      "epoch:55 train_loss:0.080530\n",
      "epoch:56 train_loss:0.078996\n",
      "epoch:57 train_loss:0.077459\n",
      "epoch:58 train_loss:0.076095\n",
      "epoch:59 train_loss:0.073001\n",
      "epoch:60 train_loss:0.071157\n",
      "epoch:61 train_loss:0.069919\n",
      "epoch:62 train_loss:0.069178\n",
      "epoch:63 train_loss:0.066533\n",
      "epoch:64 train_loss:0.064671\n",
      "epoch:65 train_loss:0.062822\n",
      "epoch:66 train_loss:0.061324\n",
      "epoch:67 train_loss:0.059663\n",
      "epoch:68 train_loss:0.057965\n",
      "epoch:69 train_loss:0.056870\n",
      "epoch:70 train_loss:0.055834\n",
      "epoch:71 train_loss:0.054099\n",
      "epoch:72 train_loss:0.052748\n",
      "epoch:73 train_loss:0.051535\n",
      "epoch:74 train_loss:0.050273\n",
      "epoch:75 train_loss:0.049392\n",
      "epoch:76 train_loss:0.048837\n",
      "epoch:77 train_loss:0.046585\n",
      "epoch:78 train_loss:0.045692\n",
      "epoch:79 train_loss:0.044850\n",
      "epoch:80 train_loss:0.043331\n",
      "epoch:81 train_loss:0.042540\n",
      "epoch:82 train_loss:0.041714\n",
      "epoch:83 train_loss:0.040682\n",
      "epoch:84 train_loss:0.039926\n",
      "epoch:85 train_loss:0.039651\n",
      "epoch:86 train_loss:0.038228\n",
      "epoch:87 train_loss:0.037356\n",
      "epoch:88 train_loss:0.036494\n",
      "epoch:89 train_loss:0.035490\n",
      "epoch:90 train_loss:0.035416\n",
      "epoch:91 train_loss:0.034042\n",
      "epoch:92 train_loss:0.033675\n",
      "epoch:93 train_loss:0.032613\n",
      "epoch:94 train_loss:0.032275\n",
      "epoch:95 train_loss:0.031416\n",
      "epoch:96 train_loss:0.030710\n",
      "epoch:97 train_loss:0.030059\n",
      "epoch:98 train_loss:0.029711\n",
      "epoch:99 train_loss:0.029077\n"
     ]
    }
   ],
   "source": [
    "dnn = ScratchDeepNeuralNetrowkClassifier(epoch=100) \n",
    "\n",
    "dnn.fit(X_train[:4000], y_train_one_hot[:4000], X_val[:2000], y_test_one_hot[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305833333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dnn.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZhdRZn/P3X3vr1vSUg6KyQhYQ2ECIIsIpLgCDIqioOOjk4cZ2Bm3H6IjjjqzLjNuI0igjAMoCiDohGDIBoElQCdyJKV7Eln6X2/+731++Otm3sJnXQnuenbt/v9PM997jl16lS9p06db71Vp845xlqLoiiKUvp4im2AoiiKUhhU0BVFUcYJKuiKoijjBBV0RVGUcYIKuqIoyjhBBV1RFGWcMKygG2PuNsa0GWPWDRPvPGNM2hjzjsKZpyiKooyUkXjo9wBLjxTBGOMFvgI8VgCbFEVRlGPAN1wEa+1TxphZw0S7CfgpcN5IM25oaLCzZg2XrKIoipLPmjVrOqy1jUNtG1bQh8MYMw24Fngjwwi6MWY5sBxgxowZNDc3H2/2iqIoEwpjzK7DbSvETdFvAjdba9PDRbTW3mGtXWytXdzYOGQDoyiKohwjx+2hA4uBHxtjABqAq4wxKWvtzwuQtqIoijJCjlvQrbWzs8vGmHuAR1TMFUVRRp9hBd0Y8wBwKdBgjGkBPgf4Aay1t59Q6xRFUQ4hmUzS0tJCLBYrtiknlFAoRFNTE36/f8T7jGSWy/UjTcxa+/4R56woinIMtLS0UFlZyaxZs3BDveMOay2dnZ20tLQwe/bs4Xdw6JOiiqKUFLFYjPr6+nEr5gDGGOrr64+6F6KCrihKyTGexTzLsRxjyQn6tlde5vH7vkJ3Z3uxTVEURRlTlJyg925r5s3b/oPu1h3FNkVRlAlIT08Pt91221Hvd9VVV9HT03MCLMpRcoLuDZUDkIgMFNkSRVEmIocT9HT6yM9Wrly5kpqamhNlFlCYB4tGFX9QBD0VGyyyJYqiTEQ+9alPsW3bNs4++2z8fj8VFRWcdNJJvPDCC2zYsIG3ve1t7Nmzh1gsxj/90z+xfPlyAGbNmkVzczMDAwMsW7aMiy66iD/96U9MmzaNX/ziF5SVlR23baUn6GUVgAq6oijw+V+uZ8O+voKmuXBqFZ9762mH3f7lL3+ZdevW8cILL/Dkk0/ylre8hXXr1h2cXnj33XdTV1dHNBrlvPPO4+1vfzv19fWvSmPLli088MAD3HnnnVx33XX89Kc/5YYbbjhu20tO0ANuyCUVV0FXFKX4LFmy5FVzxb/97W/z8MMPA7Bnzx62bNnyGkGfPXs2Z599NgDnnnsuO3fuLIgtJSfo/pB46JmECrqiTHSO5EmPFuXl5QeXn3zySZ544gmeeeYZwuEwl1566ZBzyYPB4MFlr9dLNBotiC0ld1M0FHaCHo8U2RJFUSYilZWV9Pf3D7mtt7eX2tpawuEwmzZtYvXq1aNqW8l56KFyEXSbVEFXFGX0qa+v58ILL+T000+nrKyMyZMnH9y2dOlSbr/9ds4880zmz5/P+eefP6q2lZ6gl1XKQkIFXVGU4vCjH/1oyPBgMMijjz465LbsOHlDQwPr1uU+0fyJT3yiYHaV3JCLx+slZv2gHrqiKMqrKDlBB4iaECalgq4oipJPSQp6nCCe5Ph+F7KiKMrRUpKCnvAE8aXVQ1cURcmnNAXdhPCk1UNXFEXJpyQFPekJ4U8XZiK+oijKeKE0Bd1bhj+jHrqiKKPPsb4+F+Cb3/wmkciJGy4uSUFPe0P4M/Fim6EoygRkLAt6yT1YBJD2lhG06qErijL65L8+94orrmDSpEk8+OCDxONxrr32Wj7/+c8zODjIddddR0tLC+l0ms9+9rO0trayb98+LrvsMhoaGli1alXBbRtW0I0xdwN/AbRZa08fYvtfATe71QHgI9baFwtq5SFkfGUErHroijLhefRTcODlwqY55QxY9uXDbs5/fe7jjz/OQw89xHPPPYe1lquvvpqnnnqK9vZ2pk6dyq9+9StA3vFSXV3N17/+dVatWkVDQ0NhbXaMZMjlHmDpEbbvAC6x1p4JfBG4owB2HZGMP0yZeuiKohSZxx9/nMcff5xFixZxzjnnsGnTJrZs2cIZZ5zBE088wc0338zTTz9NdXX1qNgzrIdurX3KGDPrCNv/lLe6Gmg6frOGsclXRog4NpPBeEryNoCiKIXgCJ70aGCt5ZZbbuHDH/7wa7atWbOGlStXcsstt/DmN7+ZW2+99YTbU2g1/CAw9JtpCojxh/EaSzyuUxcVRRld8l+fe+WVV3L33XczMCDfON67dy9tbW3s27ePcDjMDTfcwCc+8QnWrl37mn1PBAW7KWqMuQwR9IuOEGc5sBxgxowZx55ZIAxAPDJAqKx8mMiKoiiFI//1ucuWLeM973kPF1xwAQAVFRXcf//9bN26lU9+8pN4PB78fj/f+973AFi+fDnLli3jpJNOOiE3RY21dvhIMuTyyFA3Rd32M4GHgWXW2ldGkvHixYttc3PzyC3N47mHvs6SdZ/nwAfXMGX6KceUhqIopcnGjRtZsGBBsc0YFYY6VmPMGmvt4qHiH/eQizFmBvAz4L0jFfPjxRMUrzwRHRiN7BRFUUqCkUxbfAC4FGgwxrQAnwP8ANba24FbgXrgNmMMQOpwrUeh8B4UdP2uqKIoSpaRzHK5fpjtHwI+VDCLRoAvJIKejKmHrigTEWstzoEct4xkOPxQSnLOn9956KmYeuiKMtEIhUJ0dnYek+CVCtZaOjs7CYVCR7VfST767y+TD0UnVdAVZcLR1NRES0sL7e3txTblhBIKhWhqOrrHekpS0ANuqmImroKuKBMNv9/P7Nmzi23GmKQkh1wCzkNPq6AriqIcpCQFPRSuAsAm9TN0iqIoWUpU0N3ToQkVdEVRlCwlKeiBQIiU9aiHriiKkkdJCrrxeIgRxCT15VyKoihZSlLQAWImiCelHrqiKEqWkhX0uAniSamHriiKkqVkBT1hQnjTKuiKoihZSlfQPSG8af0MnaIoSpaSFfSUJ0RAPXRFUZSDlKygJ71l+DLxYpuhKIoyZihZQU97QwQz6qEriqJkKV1B94UJWPXQFUVRspSsoFtfiCAq6IqiKFlKVtAz/jBl6qEriqIcpGQFHV+YoEmSTqWKbYmiKMqYoGQF3QTKAIhF+otsiaIoytighAVdXqEbi+qHohVFUWAEgm6MudsY02aMWXeY7cYY821jzFZjzEvGmHMKb+YQ+QbCAMQjKuiKoigwMg/9HmDpEbYvA+a633Lge8dv1vB4g+KhJ9RDVxRFAUYg6Nbap4CuI0S5BrjXCquBGmPMSYUy8HB4g+Khq6AriqIIhRhDnwbsyVtvcWEnFF9IPhSdjOmHohVFUaAwgm6GCLNDRjRmuTGm2RjT3N7eflyZ+kMy5JKOqYeuKIoChRH0FmB63noTsG+oiNbaO6y1i621ixsbG48r00BZJQCpuH61SFEUBQoj6CuA97nZLucDvdba/QVI94gE3JBLOqFDLoqiKAC+4SIYYx4ALgUajDEtwOcAP4C19nZgJXAVsBWIAB84UcbmEwjLTdFMXAVdURQFRiDo1trrh9lugX8omEUjpKy8SvJP6JCLoigKlPCTomVlMuSCCrqiKApQwoLu9fmIWT+kVNAVRVGghAUdIGaCeJL61SJFURQodUEnhEmpoCuKokCJC3rCBPHqkIuiKApQ6oLuCeFNx4pthqIoypig5AXdp4KuKIoClLigp7wh/BkdQ1cURYFSF3RPGf6MfihaURQFSlzQM74QQatDLoqiKFDigp72hQla9dAVRVGgxAU94ysjpB66oigKUOKCbv1hQsTBDvk9DUVRlAlFSQu68ZXhNZZEXGe6KIqilLSgE5B3osci+hk6RVGUkhZ0E1RBVxRFyVLSgu4NyIeiE9H+IluiKIpSfEpb0INZQdfP0CmKopS4oMuQSzLaV2RLFEVRik9JC3qoZgoAsd62IluiKIpSfEpa0KsnTQcg2d1SZEsURVGKT0kLel3jVBLWi+3bX2xTFEVRis6IBN0Ys9QYs9kYs9UY86khts8wxqwyxvzZGPOSMeaqwpv6WgJ+H52mFu9g62hkpyiKMqYZVtCNMV7gu8AyYCFwvTFm4SHR/gV40Fq7CHg3cFuhDT0c3d4GymI6hq4oijISD30JsNVau91amwB+DFxzSBwLVLnlamBf4Uw8MgOBRiqS7aOVnaIoyphlJII+DdiTt97iwvL5V+AGY0wLsBK4aaiEjDHLjTHNxpjm9vbCiHC8bBJ16c6CpKUoilLKjETQzRBhh77e8HrgHmttE3AVcJ8x5jVpW2vvsNYuttYubmxsPHprhyBdPoVyoqR1LrqiKBOckQh6CzA9b72J1w6pfBB4EMBa+wwQAhoKYeBweKtPAqC3TacuKooysRmJoD8PzDXGzDbGBJCbnisOibMbuBzAGLMAEfRRGdgO1DYB0Nu+azSyUxRFGbMMK+jW2hRwI/AYsBGZzbLeGPMFY8zVLtrHgb81xrwIPAC839rR+epEeYMIerRTPXRFUSY2vpFEstauRG525ofdmre8AbiwsKaNjJpJMwBIdo/axBpFUZQxSUk/KQrQ0NDAgA1h+/VpUUVRJjYlL+ghv5cOU4tPnxZVFGWCU/KCDvK0aCimgq4oysRmXAj6YLCRykRHsc1QFEUpKuNC0ONlk6nNdMLoTKxRFEUZk4wLQc+UTyFAChvRVwAoijJxGReC7qmSp0X72/cME1NRFGX8Mi4EPVgnDxf1te0usiWKoijFY1wIevZp0Yg+LaooygRmXAh6zWT3bdEefVpUUZSJy7gQ9Ek1VXTaStBviyqKMoEZF4JeHvTRQS2+iD5cpCjKxGVcCDpAt6+RkH5bVFGUCcy4EfRIoIEq/baooigTmHEj6PHwFKozPZBOFdsURVGUojBuBD1TMRkPFjtwoNimKIqiFIVxI+he97RopHNvkS1RFEUpDuNG0AN1Mhe9v3V7kS1RFEUpDuNG0MumLiRhvaRb/lxsUxRFUYrCuBH0qQ01bLQz8R1QQVcUZWIybgR9em2YDWYu1d3rIJMutjmKoiijzogE3Riz1Biz2Riz1RjzqcPEuc4Ys8EYs94Y86PCmjk8Ho+hq/YMQpkIdLwy2tkriqIUHd9wEYwxXuC7wBVAC/C8MWaFtXZDXpy5wC3AhdbabmPMpBNl8JHwTDsXeiC9pxnvpAXFMEFRFKVojMRDXwJstdZut9YmgB8D1xwS52+B71pruwGstUV5Bv+kk8+gz5bRv+3ZYmSvKIpSVEYi6NOA/E8BtbiwfOYB84wxfzTGrDbGLB0qIWPMcmNMszGmub298I/pn95Uw0uZOdi9awqetqIoylhnJIJuhgg79GvMPmAucClwPfADY0zNa3ay9g5r7WJr7eLGxsajtXVYZjdUsMEzl6rezZCMFjx9RVGUscxIBL0FmJ633gQc+iWJFuAX1tqktXYHsBkR+FHF6zF015yBlzQceHm0s1cURSkqIxH054G5xpjZxpgA8G5gxSFxfg5cBmCMaUCGYIryyKZ3xnkAZPY8X4zsFUVRisawgm6tTQE3Ao8BG4EHrbXrjTFfMMZc7aI9BnQaYzYAq4BPWms7T5TRR2LWrJPZZ+sY3PFcMbJXFEUpGsNOWwSw1q4EVh4SdmvesgU+5n5F5fRpVbyYOZk37NMbo4qiTCzGzZOiWU5prGA9p1AxuAciXcU2R1EUZdQYd4Lu83roqTtTVnT6oqIoE4hxJ+gAgRnnErFB7IZD790qiqKMX8aloM+bfhKPpM/HrnsI4v3FNkdRFGVUGJeCfvq0an6cvgxPMgLrHy62OYqiKKPCuBT0U6dUsi24kAOBmbDmf4ttjqIoyqgwLgXd5/Vw+cLJ3Ju4BPY2Q+v6YpukKIpywhmXgg5w5WlTeCD2ejIeP6y9r9jmKIqinHDGraBfPLeRqL+G9VVvgJd+DMlYsU1SFEU5oYxbQS8LeLl4biN3DlwE0W7Y8Itim6QoinJCGbeCDjLs8suBeURr58OTX4JUotgmKYqinDDGtaBfvmASHo+XRyZ/BLp3wPM/KLZJiqIoJ4xxLeg14QDnz6nj9pZZMOcy+P1XZPhFURRlHDKuBR1k2GVbR4Tdiz8NsV546j+LbZKiKMoJYdwL+psXTgHg/1qqYdFfwbPfh64dRbZKURSl8Ix7QZ9SHeLNCyfzv3/aycDrbwavH379KbCHfhZVURSltBn3gg5w4xtPoS+W4t71Cbjs0/DKr2HDz4ttlqIoSkGZEIJ+ZlMNl8xr5K6ndxA9ZzmcdDas/H96g1RRlHHFhBB0EC+9czDBA8374OpvQ6QTfnPr8DsqiqKUCBNG0M+bVcfrZtfx/ae2EW88HS74B1h7L+x4qtimKYqiFIQJI+gAN71xLq19cR5sboFLb4G6OfCT98K+PxfbNEVRlONmRIJujFlqjNlsjNlqjPnUEeK9wxhjjTGLC2di4bjwlHoWz6zlW09sYcAG4L0PQ7AK7r0G9q4ttnmKoijHxbCCbozxAt8FlgELgeuNMQuHiFcJ/CPwbKGNLBTGGD7zlgV0DMT5/u+3Qe0seP8jEKqGe98Ge54vtomKoijHzEg89CXAVmvtdmttAvgxcM0Q8b4IfBUY0++pXTSjlqvPmsodT21nX08UamfC+38F4Vq45ypY/T2do64oSkkyEkGfBuzJW29xYQcxxiwCpltrHzlSQsaY5caYZmNMc3t7+1EbWyj+39L5WOA/H9ssATUz4G9XwSlvkoeOHng3DHYWzT5FUZRjYSSCboYIO+jCGmM8wDeAjw+XkLX2DmvtYmvt4sbGxpFbWWCaasN88KLZ/OzPe3mppUcCw3Xw7h/Bsq/Ctt/Bd8+D5rshky6anYqiKEfDSAS9BZiet94E7MtbrwROB540xuwEzgdWjNUbo1n+/tKTaagI8PEHX6Q/lpRAY+B1H4blT0LjqfDIR+H7l8C2VToMoyjKmGckgv48MNcYM9sYEwDeDazIbrTW9lprG6y1s6y1s4DVwNXW2uYTYnGBqAz5+da7F7G9Y5CP/uQFMpk8wZ58moyrv/MeiPXAfW+DOy+DdT+DdKpoNiuKohyJYQXdWpsCbgQeAzYCD1pr1xtjvmCMufpEG3giufCUBm79i4U8sbGN/3x886s3GgOnXQs3NsNffBNiffDQB+Drp8IPr4NVX4KdfyyO4YqiKENgbJGGEhYvXmybm4vvxFtr+fTD63jgud18411nce2ipqEjZtKweSVs+hXsewE6NoPNwKIbYOmXIVg5uoYrijIhMcassdYOOaTtG21jxhrGGD5/9Wns6Bjg4w++iMHwtkXTXhvR44UFb5UfQHwA/vAN+MPXYecf4K3fhqbzIBAe3QNQFEVxTHgPPctgPMWH/reZ1Ts6+cpfnsl1500ffieAXc/Aw8uhZ7esh+uhYgp4fYABfxnMuRQWXA2TFshQjqIoyjFyJA9dBT2PaCLN8vuaeXpLB1+45jTed8Gske0Y64Mtj0PPLujZAwOtMhxjMxDpgr1rAAv1p8D8ZTBvGUx/nRN9RVGUkaOCfhTEkmlu/NFantjYxgcunMVnrlqAz3uc7zDrPyBj7xt/KcMzmSSU1cLsi+U362KonCLevMenXryiKIdFBf0oSWcs/7FyI3f9YQeXzGvkv9+ziKqQvzCJx/rkwaVXHoMdv4e+va/e7vHByW+Eiz4GMy8oTJ6KoowbVNCPkQee281nf76OmfVh7nzfYuY0VhQ2A2uhazvsfka+npSMQbQLXvqJfIBjxgUwfYnMfc8kofIkaFoMU8+BYIFtURSlJFBBPw5Wb+/k73+4lmQ6w7evX8Rl8yed+EwTg7D2Plj9XehvlQ9be7wQ65XtxgN1J0PDXBmXr54OZTXy1siKydA4X4ZvFEUZd6igHyct3RGW37uGjQf6+OfL5/F3l84h6POOviHZG6wtz0PbBujYCl3bIJ14dTzjEaGvnQ2+oPuFZNz+4K9G/oNVEt8Y8AagYZ40HoqijElU0AtANJHm5p++xIoX99FUW8Ynr5zPW8+cisdT5BuYmbQM10R7xIPv3Q2tG0Twe3ZBOgmpOCSjEi8dP3J6ZXVwyuUyjh9ukJk43oCbjjlZGoGhbtpaqzdzFWUUUEEvIE+90s6XHt3Exv19nNVUzb9fewanT6sutlkjJyvs0R75j/fL9Eqs3LDd8XvY8huIdAy9vzcgop/18pMRGGiDwXZ5DfGCt8qc+8mn5fZJJyEVk7y9fmkYsr2AVFzm8KdiMOk08EyoryIqylGjgl5gMhnLw3/ey5ce3UTXYJy/uXA2H71iHuXBcTKvPJORVxskBkWM0wkR+P5WGDggQz+xHmkU/GGoaBRv/sBL8tHtzDAvMDMeJ+p+6GtxDQqSxilvghnni/DbjPP8PdIAWOvy7RbbGubJ07mTFgw/TBQfkDR9wcKUkaIUCRX0E0RvNMlXfr2JHz27m6nVIT56xTyuXTTt+OetlzLRbnjl8dx0TGNkKqYvJDdqU3Ho3w99+6WhqJsjPyxs/S1s+63M8DkSxiPpJSOy7iuTG8K+gIQHK2U9WCW9h65t8rAXRmYK1c6EqqlQ3ii/YJUMLXn80gPxhyTNVBS6dkD3DmkQ6k+G+rnSE/EFJa43IA2FNyBhoZqhexnWStkMdkjvprxBh6iUY0IF/QTz/M4uvvjIBl5q6eXkxnI+dsV8lp4+BW+xx9dLkUwaeltE7IwTRpvJfWgkVC2iaYxM+dy7Bva/CPE+SCVk6CYxIL2HeJ94/fWu0UglZHinZ5c0KgPtkOgf3qZwPfjLoXcPed92GRqPD8onyT42I/csUnFpWPLvX/hCUDXNvfvHHasvKD0ef1jiZofGPF45jvJ6CFS6hsDIsUY6pfeUTkHFJOn5VEyShqpikqQV6ZD8o92vvteRikujmoq7RskvdgXKpZELVopdmTTYtAyZJSOQiIit4Xr5ZZJSloNtrpE1koevTD4cE66X/Pr2Qu9eiVMzA2pmio02I3ZkUu4Gvft5fLme12CHPKAX6RTHINtgHyzjhGsw2yWOzbhGNyiNZ+0s+Xl8EicbLzv0aNNuGLFOGvRkTOxM5X1RM52UOhXtkbIIVsqwY7DKPRDo6mtyUByAZESchOzEhExK0kvF4czr4LwPDV/3hkAFfRSw1vLY+lb+6/HNbGkbYFa9fBXpHedOpyygs0bGLMlobmgpkxJhSUblwvP4oG62iAfIRd61XYQpnXC/ZG5YKhUT4RxoExH1+HIiWd4gvYPyRhGQnt2STiqee01EKv5qwczep8ik5JOIg+2y3VrAStrhBkk7K1T9ByT/VPSQAzUQcjOastd8Vmi8ASc2CRHH+MDhb54brzQSqZgIeT6hamn4sJJHMgrx3tx2jw8qp4og9+7J9bBGivGI4KbiQzfEwWopi3C9NATZBmugVcrmUELVuVlfxiPnJdIlx5ZtWH3BXANovM6hqJZjiPfLEGCsL3cOsVIGwQqJk8nIuUjFcz1VXxDOeAec876jO/5sMaigjx7pjOXRdfu58+kdvLinh5qwn3efN4P3XjCTaTU6N1wZBayVRmqwTf7LG3MzlkZKKu5umFsRR+MRgfIGROCsle2RTmlYyhuHvj+RTopQZtLijWc9bmvF6x5sd89Z+OSHzfXIbEYaGmtfLdQgPZJEv9jldY3SkW6oxwekZ5ZJSQ+qvEHyLUFU0IuAtZY1u7q56w87eGz9AQDevHAKf3fpyZw9vabI1imKUqro+9CLgDGGxbPqWDyrjr09Ue5fvYsHntvNr9cf4A1zG7jpjXNZMruu2GYqijKOUA99FBmIp7h/9S7ufGo7nYMJzmyq5obXzeStZ03VcXZFUUaEDrmMMaKJNP+3Zg/3PbOLLW0DVIV8vP3cJm44fyYnF/oFYIqijCtU0Mco1lqe29HF/c/u5tfr9pNMW15/cj3vXNzEFQunUDFeHlRSFKVgqKCXAO39cR5s3sOPnt3N3p4oIb+Hy0+dzLIzpnDJvEYqC/U+dkVRSprjFnRjzFLgW4AX+IG19suHbP8Y8CEgBbQDf2Ot3XWkNFXQhyaTsazZ3c2KF/ax8uX9dA4m8HsN58+p500LJvOmhZN1+qOiTGCOS9CNMV7gFeAKoAV4HrjeWrshL85lwLPW2ogx5iPApdbadx0pXRX04UmlM6zd3cNvN7bym42tbG8fBOC0qVVcdcZJvPPcJiZVhYpspaIoo8nxCvoFwL9aa69067cAWGu/dJj4i4DvWGsvPFK6KuhHz/b2AX6zoZXH1h9g7e4evB7DmxZM4tpF0zh/Tj014UCxTVQU5QRzvPPQpwF78tZbgNcdIf4HgUcPY8hyYDnAjBkzRpC1ks+cxgo+fEkFH77kZLa3D/CT5/fw0JoWHlvfijFw6pQq3jC3gWWnT+Hs6TUYffmTokwoRuKhvxO40lr7Ibf+XmCJtfamIeLeANwIXGKtPeKXFNRDLwzJdIYX9/TwzLZOntneyfM7u0imLdNqynjjqZNYOLWK+VMqmT+5cvy83ldRJjDH66G3ANPz1puAfUNk8ibgM4xAzJXC4fd6Dj6RetPlc+mNJvnNhlZWvryfn65t4b7V8pZCr8eweGYtl506iYvnNjJ3cgX+ifyaX0UZh4zEQ/chN0UvB/YiN0XfY61dnxdnEfAQsNRau2UkGauHfuLJZCx7e6JsOtDP2t3dPLm5nY37+wAIeD3MnVzBaVOrOG9WHefPqWd6XbjIFiuKMhyFmLZ4FfBNZNri3dbafzfGfAFottauMMY8AZwB7He77LbWXn2kNFXQi8OB3hirt3eycX8fG/b3sW5vL90ReQ1qdpjmioWTOX9OPQGfevCKMtbQB4uUw5LJWLa2D7B6eydPb+ngD1s6iCbTVAR9nD6titOmVnPa1CrmTa5kTmM54YCOwytKMVFBV0ZMLJnmD1s6ePKVNl7e28em/X3EU5mD26fVlHH2jBrOn13H6+bUc0pjBR79MpOijBr6+lxlxIT8Xt60UJ5IBXm4aUfHIFvaBtjWNsArbQM07+ziVy/J6FrQ52F2QzlzGvJkojQAABgcSURBVMtZNL2Wy05t5OTGCp0yqShFQD105aix1rKnK8qzOzp5pbWf7e0i+Lu75JNiTbVlLJlVx9zJlZwyqYJ5kyuYXhtWT15RCoB66EpBMcYwoz7MjPpXz4rZ2xPlyc1trNrUzp+2dfKzP+89uK3M72Xe5ApOnVLF6U3VnDmtmvlTKgn59T3wilIo1ENXThh9sSRb2wbY0trPpgP9bD7Qz4b9ffREch8Xri7zM6kyyPS6MOfOrOW8WXWc2VStQq8oh0E9dKUoVIX8nDOjlnNm1B4Ms9bS0h3l5b29bGsboK0/Tnt/nG3tA/xuUxsg3yCuCwdoqAgyqSrIzPows+plnH7BSVVMqQrpGL2iDIEKujKqGGOYXhce8iGm7sEEz+/sYv2+PtoHROhb+2KseGEffbHUwXh15YGDUynnTqpg7uQKTm6s0JeTKRMeFXRlzFBbHuDNp03hzadNeVW4tZbuSJJt7QNs2NfH+n29bNjfxw+f3UUsmZtSWVceYE5DOZOrQzRWBGmoCDCpKsSUqhAnVYeYXhfWoRxlXKOCrox5jDHUlQeoK6/jvFl1B8OzrzbIzrTZ3jHA9vZBNuzro6M/Tn88dUg6MKMuzNxJ7uase3CqqbZMh3CUcYEKulKyeDy54ZvLF7x2eyyZpq0vzv7eKAf6YmxvH2Rr2wCvtPazanM76YxMCPB6DFUhH1XuBq3Mq69gclUQjxP6qjI/50yvpTqsnwJUxi4q6Mq4JeT3Djm9EkTsNx/oZ92+Xvb1ROmLpuiNJjnQG+N3m9p5sLnlNfsYA/MnV3JWUw1VZT7CAWkEZjeEmdNQQVNtGT59g6VSRFTQlQlJyO/lrOk1nDW9ZsjtfbEkHf1xLGAttPXHaN7ZzXM7uvjtpjYiiRSRRPpV+/i9hmk1ZUyvC9NUG6ahIkBNOEBt2E9teYBat1xTFqAy5NMHrZSCo4KuKENQFfJTFcoNr5wyqYLXn9zwqjiZjKUnmmRHxwDb2gfZ3j7Inu4ILV0RHt93gO5IgsxhHvMwBiqDPppqw8xplCGeqdUhGiqCNFQGqQ37qQz5qQz59L31yohRQVeUY8Tjyd2sPXdm3Wu2ZzKWvliSrsEE3ZEkPRH5743KryeSYHdXhJdaeln58v7Din/A5yHk81AW8FIbDtBUG2Z6XRnTasporAxKI+Bm9dSGA+r5T2BU0BXlBOHxGGrCgRHNj4+n0nQMJOjoj9MxEKcnkqQvlqQvmiKSTBFPZogm0nQOxtnTFeFP2zpeM+QDcoM3O7RTGw5QW+53jU6AuvIg9QeXA1SF/JQHvVSEfAR9Op1zPKCCrihjgKDPy7Qa8bpHgrWWvmjq4ANYHQO5X+dAgu5Igp5Ikh0dg6zZ1U13JHlwVs9Q+L2GiqCPipCP2nCA+vIA9RVBasr8VJX5qS7zU1XmozIow0BVLrwq5KM8oPcDxgoq6IpSghhjqA77qQ77OWVSxbDxMxlLbzRJ52CCLvcbiKcYiCXlP55mMJ5iIJ6iazBBx0CCzQf66Ykmh+wJHErI7yEc8BHyeQi4X2XIz5TqEFOrQ9RXBCkPeCkL+AgHvJQFvJT5vVQEfVSXyU3j8oBXnwc4TlTQFWUC4PEYmWlTfvSvR0ikMm74J0l/LOV+uSGhgXiKaDJNJJEilsyQSMmvJ5pgw74+frux9VVP9B4On8dQ5ndi7wQ/5PcSDngJB3xUBL2UB30Hw0N+Dz6vB5/H4PUYyoM+asr81IQDlAdln2zjEfZ7J8SUUhV0RVGOSMDnOXjj9Viw1hJJpIkk0kQTaSLJFFG3PBBP0RNJ0h1J0BtNEk2miSVlWzSZJprMEImn6I5EGYynGHSNRyyZPuxN5MMeh9dDOOil3Al9wOfBGDAYAj4PNW5oqTzow+c1+L0e/F5pKCqDPsoCPvxeaTz8Xg9lrrEpC2QbGC9Bn+fgv89jRr3HoYKuKMoJxRgRxfJg4eTGWksybUllMqQzllTaHmwceqKJg8J/sBE52KDI8FIkkSKRyrjnDCzxVIYDfTE2HehnMJEinbakMpZ46ugbjiwew6t6EEGfCH3Q7+E9S2bwoTfMKVh5ZFFBVxSl5DDGEPAZAuSGUWrLA0x/7ezR48JaSyyZkWGlRJqka0ASqQyxbIPhegzyyxzcFk9lSGUsqbT8J9IZ4skM8VT6mHs7wzEiQTfGLAW+BXiBH1hrv3zI9iBwL3Au0Am8y1q7s7CmKoqijC7GmINj+qXAsHcJjDFe4LvAMmAhcL0xZuEh0T4IdFtrTwG+AXyl0IYqiqIoR2Ykt32XAFuttduttQngx8A1h8S5Bvhft/wQcLnR+UeKoiijykgEfRqwJ2+9xYUNGcdamwJ6gfpDEzLGLDfGNBtjmtvb24/NYkVRFGVIRiLoQ3nah973HUkcrLV3WGsXW2sXNzY2jsQ+RVEUZYSMRNBbgOl5603AvsPFMcb4gGqgqxAGKoqiKCNjJIL+PDDXGDPbGBMA3g2sOCTOCuCv3fI7gN9Za49x9qaiKIpyLAw7bdFamzLG3Ag8hkxbvNtau94Y8wWg2Vq7ArgLuM8YsxXxzN99Io1WFEVRXsuI5qFba1cCKw8JuzVvOQa8s7CmKYqiKEeDKdbIiDGmHdh1jLs3AB1DLB9p21hYHit2lKp9pWTrWLFjPNg6Vuw4UbYeLTOttUPPKrHWltwPGep5zfKRto2F5bFiR6naV0q2jhU7xoOtY8WOE2VrIX/j/32SiqIoEwQVdEVRlHFCqQr6HYdZPtK2sbA8VuwoVftKydaxYsd4sHWs2HGibC0YRbspqiiKohSWUvXQFUVRlENQQVcURRknlNQXi4wxdwN/AbQh72e/F5iCvAisHOhBjukh4AtAMzAf2AakXbxtwDnAVGA3EAFOBbqRj3NMAWqAFPACMMeFVwGTgSQQR95X04O8mKzCpR9xyzHgEWdrBRAF/C7NncBct1+Hs7fGrQ+69Z68sBTS8PqAjAsLIG+0TAJlLu3s2FkKaHVxq4BJzraU2x5z+/jcPinkCWCvOy7jllNuv4CLl3H5eIE+IJxnm3FxE+4Y/Mg82x63v8flmy2nrCORziuXTe5cpZDnE5pcvh3I2zyty7PH7bMTOMXluRN5l9Bq5Pz+gyvzV4B5Lo2Yix8HNgOnuzSzx2aBoCvXFuA0V74ZF26QOlKTV04Bt5wEQuTqT7accXFSrryz5ZBd7nfnInsecOmavHINuPIOAXtduQbdPoPOprQ7Lye7dGKujLL/IRc/6pZ9zm5cWim3Xk6urmQ/qdOL1PWUK4uAO96Es30AqWfZY0i7fGuG2Me4vLPxLLk6nt2WreNBd9xZO7J1zONs3QHMAGqdLdlzOQhUkqtXGXI6l7Uh7tKN59lqkbo1yR1z2G0zLn2/O4408BSwCDnX2fMMsB+pq363n3XxM0hdnO22JYA/AtchdeBbwFWIfrzfWruWY6TUPPR7gKVuOQV83Fq7AHgdUkjXA2e7OF8HNrq4l1lrzwZeAn5trZ2DVMIlwFuRE34J8sqCEPBlYKsL/1vkIvqliz8IPA2sQS6Qa114P/I07evcch3wMnIyH3DhB9z+FzrbznD7t7p9LgHejghfL9LwNCOV42zgfneczyMNVh/yDp3bkMatFakczyIX2xYXp9+l9UGkIi9BxHO/C9+HXJjnIo1cArjM2Tjg7PqVs/8A8PdIY3eZK5d9bvl/EGFpduenA2nU/h5p4F4ALgVmAS+6faJIA/2U23cAuNudtz7gey6dPYh4rQeedHHaEPG/x9l1KnA+ciFtcGXyElLPv4+8y/9pF27dOd6HXJSPumP/ASLovcjFeZs7Z38CPuviTHd29bvlf3FlttHt1+PCr3Lhs621XncM0xFh3gl8wtkfAW5xtvUBNyMfldntbPw0Ijqr3bn9JvB/wCrgCWAdIla9rnw+jTg8UeBfXN4Pu/C9wI8QMdrtztMpLu8E0ijc5vZd7Y6t1cX5niuLucBnXPwXXL7Z8KuQayO7z0y3PNedI4s0lvsQgbwJqadB4EZ3PB6kcfyUs+8m4HGkftwE/MSlsdltty7800jjc5Mr56Rbzja6HyXXcJ0HbEde873YHbNB6sLnkXrkdeX8qFteAnwHuMLt2+9sXeJsnwFcgFxnMcS52Iu8DmW1K9MNwL8juvBJd57mut9yV8bHTEkJurX2KdxbHK21+7MtmbW2HymobOsYBl6PXJwAGGOqgIuR985grU1Ya3uAi5BWtAOpJF1IRQH4BXJiq5CT3OXizUMqUsRau8qFD7p9upByPQX4ogvb5cLrkEra6mxoQy6kOpfWWqRChpALdxpSMdNu+bMuvSAigOsQAXgKqaQvIBdqr7PhPqSyH3D7XwOsBSZZa7e65WmIV7LLLTchld4iF3fWg/wOOU8sK74WeI6cx1iBCM9/Ozu9iFh9BPmKVXafHrdcRs7TvwCp8DHgLUhjWu6Wv4o0qmXAf7ryeQvSmFS45S1IDypKrjfxFleeuxCh+YErl6vdf4/7zyA9BIDfA29AGhby8sOdkyzZMsDZGUTqSD4fceci4dYz7n+yK6e7XHkHXPnOd8f5HeB2RAz3unz9roxuQxrEixDh9CEOTPb9STPd/je59W+6ur/YhU8GnnN1fwbQY63dBZwFZNzyc+Q8WQtsc+E9QNQtn+nS/0dnQ7cL/wjwm7x9zkSEbTdSzzLINXSSS7vbHY8HuUbucuWaRhpRrwtfmxenzIVnr+9s+Pvcfp1uuwepfyHkOul2Ye2IkDa57cuAr7l0U8AfkOt3kzu2WW55Gbnr8TmXR4cL/yAi8m9C6s4WpKcw2dl+DVJPNiIfA5qPOG/XAPdaYTVQY4w5iWPlRDytdCJ/rnDXDRG2G/HGBlzhn4t4gxFXoBuQbto9wJ+RylCOeHoPuf263Ik/G/F0nnHx0/l5IxVjNfIlp2x4H9IA7EMu4DtceNrZthGpLF9x+Q8iXsLFSAOSQDy4vYhn344IaIzc8Mkst/w00rPY7cJ/iXgwKXec/+zsqXL/qTy7+xAPejUi9EvJeTrZruujzgaLXNQvOHvbXZwBRGRfcMe3jdzwxCoXbpEL6yUXHkd6BH0ura8iQpt2v1aXRgdwucsj6c7jO93yPuQC2I/0eF5x5dOJeNV9Ln7K/ba4fLMN/rOIV3+rszFBrlu+2eXdRm6oZy0imhmXxsa88B6XdoJc130tueGEqFuOuOPtd/tkbU668Gza97vljFve5JYPuOWfufO2x8VPu/O5z+Vxf17e3Xl5d5Abmnnc2TXgyisN/NDV4RQQc8t3u32fROr0jS48e43tcWn80YXHkWvnpbxzvhNpHFcg3uvFzobsMVsXZ8Ctp91yp8s7K/zN5OpCjwtP5dlgXXlmh3D2khv+e9ltS7j9stdmHLgzL/xOco5FEql/i1xZ7UJ6I0lX7vtcvDuR+pZxNve4OK3O5rjbvp5cwxgHPuTKLOLSewS4KE/LfgssPmZ9LLZAH6+gIx7aGuAv3fq73Ek9HRH037jwK1yhftitfwvp+nQiAtmIeEFrXWUZRLykuxhe0L/mTp5Buv0JZNhmlluehIyfpdwJnoWI4A6ki/UcsNul9V5XUV9AhD97wWePc8DZuxH4S1fZVmTLAPg3l+cNbp8E8H7EW0giF2WF27/VVcx+4Ksu/1tcvM3IRZp0ZXmay3svcl9hFdIQfs8tX0pOfE535bcKuTCSSFd6FfBPiOe1yh3HK4iInu7CU+4cRIC4s+lL5MbKv+j+70Q8qZ2Ip9UHdOQJzE7Ea04jvR+QHkt2eGWD238q0qNoQy7ge/PO08Xu3KXcubjChd+JDEFl47QgjV12eTMyTNXu8rsYuNLZ9XNyjeWHgf8i14DE3PJdiEdtEQFZjAzbZRCRXeyW/0zufsldrvyzy115af21W97oyvwRpO5nnZi1bnsX0lvoQATq9+5/MtIIxt1ytSvXb5MbVz4N8X7bXHlNRnrJabf8faQebESutc84W7O91wzi3Z9FbrhuvivDP7j925HG4QBSZz9CztG4idzY/keQOp9Artdn3TnZgdTf7BBM9tpqRXpc2YZpk1vf7s7JU67cW936rrzlP7rlrKPT6s5L1hHrRd5UG0McrU5yw7WdSD06VNDPPVZ9LKkhl0MxxviBnyJexs9c8NmIYD2FjJleaIy5H7mIehFhAxGjK5EL8BVrbbu1NomMTz6JnPwu95/K6wb5kEqbteGvkRZ9j5UzMhOp2B9DKqIfabEbkAoTdrtmhwbeDiwA+tzx3ODyOM/l042Mo/4UEe69yMXzqDuWtyJdxR8invpSpCv4b0hF9yLj7SsQMU+7tO5EKuD7nI03O7u+7OJku7OtLs0q5EIqQ8TTIo3XP7jyusSlM8eVfRnS3b4c8aiNi+d39j+LjN83khtCOsvZO8/tHzDGDCAXgh8ZIviYK+MPIOd6BnKBVQL1xpjsTbiZyAVjgDKXzrUur6Uuj3OQnsLXEAH5CnLhRVz5LnH29Ljj70YaoCuQXsP/ueMOIcNmP0eGvKYAb0QajSiwxFr7GCI+lyMNerYufs2V5bOurFNu/4Q7D9mbgq0u3lVInW11dtYj9eh6pI5l6+Amt/8URFDS7tyc5Y7zSqQB9SFDRVlvdBkigq3umDa58noP8LS1thVpINLA3yHOj3HlNQmpswkXr5HcDeR3IdfFn6y17a4cM8h9Jz9SF89A7rn0uXN4oSuzqYjQbQA+jvSsw+44ypDrfYE7T4MunUFyQ5+NSAP2KDJs1Yc4FnuRuvl5Z98AUg9uQBrCAHCztfZiV1b/4eI0uXLzIY7IN5DefAr4vLV2ETmv3CAC3ouM/fvdMe5HnLqRfEBoxJSsoLuPUN+FtPj3GWNq3KYvIF2+9yGt9O+ttTeQu4HR4+JdjlSMFcD5xpiwS/MtiID6EY93BbmbjyBjn79wy2FECD/k4oN4Am1uv4uQk3wOIq4pcmPtAUQksp5yuTueAZdG9tgOIBfWRnKeRQRpaG5GLsK9SKW6yx3nw4hAfh+pHM8gNyHXOvs3Il7aNGfXbnfcIDeBk8iFnJ11swm5selx225EvMTPIV7YlUilfcil9z5EILYgF3xWjK505bQDEcTViDBscfv8jzveekQ8t1hrK5Ax2XXOzv9x2yoRD3els/FBYLu1NjuT5FcuzitAm0vnX5xd97ljex7x5v4SubiWIQ3pb5EZCOvc9uzsnSvcMdyMiMZSl8Z/IfXqPe5Yt7gy70EEeZ0x5nXOnqyX6HfbL3Rlut+d+4RbvsrlGUdE6K9c2hdZaw+4eAZpRLI3Ove7873ThWVcWJWL2+XCP4jUt1ecrde7Mt3mltuROj4ZuRZuRurMbxBe78p7BdLT6gbOcXZVkfta2XJX3mc7e7uANxpjwsj9GVz6/a6ctiJDZiFyPcMmpB6nkcbov51tSeBfXfnE3b7tiLhvRRo3gzhyVYhgbwT+BmkEfuq2T0Z6P//o7Ol25Z296XuvMeZipL7ei/RKIkhD0YY4Dd8nN2PpAWPMJa58Y+6c3YCI+ddceb/fpXG7K8P3GeF8oNdau59jpKSeFDXGPIB07RuQgm9ETlgA8dRakYvgQWvtF4wx1yOFvQO56H+HnKwAIoQXIkMhH0NOePaOv5fc1K4YcnKyjZ+HXMubJZO3PTvtKjt2V01uSpXJ256dfrUf5126/RPIya4hN8566BSwLPlpWmd31JXDLOTCnkFOiBPuWPKn43W6PLKzAvKnIUaRRitrvz/vOLNjgll7sulHkIp+BnIBh1287LSvhMtzMiIuXuQCPoB4kxWI1/Is0vvodHk1kZs2mR0Sme/s2eLKMW2tXWqMSbtj2k1uOKfVxZ2G3EBcjAiVj9zNWi+5rnRTXjn7yE0nxG0PkLtxmJ2yut/llR3nzU4nJG//dldW5e5YfS6eQUTBm1fmJi+fDDIEMNull+3h7XU21yA9oqhLI+nszPZII+4XR66fCrevcWXyfcTLvRgRvjrkxmXapZX1orP3c36DNOzZm+LZ3t98pJGd65avRRrHa5He6P+4tPOdyawYZsvCS85ByuTln73HEEXqiB/pacXITQnNTnlMu/273PJUctMebd62yry0B51t2SmH2d6FydsnjjSa1h1fMi/ckpsWmn8ddbjfyW5bErnH9lG373cQ5yACfMBa28wxUlKCriiKohyekh1yURRFUV6NCrqiKMo4QQVdURRlnKCCriiKMk5QQVcURRknqKAriqKME1TQFUVRxgn/H5ohi14jFC5NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_train, label='train')\n",
    "plt.plot(list(range(1, dnn.epoch+1)), dnn.loss_val, label='test')\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, dnn.epoch+1)));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
