{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ab5693",
   "metadata": {},
   "source": [
    "# 線形回帰\n",
    "\n",
    "線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9306d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import *\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e31b4504",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "完成例：雛形\n",
    "\n",
    "スクラッチコードの完成形\n",
    "線形回帰のクラスをスクラッチで作成していきますが、最終的なコードはどのようになっているのでしょうか。\n",
    "\n",
    "下記は、最終的なコードの概観になります。\n",
    "\"\"\"\n",
    "class ScratchLinearRegression():\n",
    "    def __init__(self,・・・):\n",
    "      \"\"\"\n",
    "      インスタンス変数初期化\n",
    "      \"\"\"\n",
    "      ・・・\n",
    "\n",
    "    # 問題6（学習と推定）\n",
    "    def fit(self,・・・):\n",
    "        \"\"\"\n",
    "        線形回帰の学習\n",
    "        \"\"\"\n",
    "        # メイン処理\n",
    "        for i in range(学習回数):\n",
    "            # 問題1（過程関数の計算）\n",
    "            self._linear_hypothesis(・・・)\n",
    "\n",
    "            # 問題2（最急降下法によるパラメータの更新値計算）\n",
    "            self._gradient_descent(・・・)\n",
    "\n",
    "            # 問題7（学習曲線のプロット）のグラフ描画時（問題5（損失関数）で作成した関数を使用）\n",
    "            self._loss_func(・・・)\n",
    "\n",
    "\n",
    "    # 問題1\n",
    "    def _linear_hypothesis(self,・・・):\n",
    "        \"\"\"\n",
    "        仮定関数の計算\n",
    "        \"\"\"\n",
    "\n",
    "    # 問題2\n",
    "    def _gradient_descent(self,・・・):\n",
    "        \"\"\"\n",
    "        最急降下法によるパラメータの更新値計算\n",
    "        \"\"\"\n",
    "\n",
    "    # 問題3\n",
    "    def predict(self,・・・):\n",
    "        \"\"\"\n",
    "        線形回帰での推定\n",
    "        \"\"\"\n",
    "\n",
    "    # 問題4\n",
    "    def _mse(self,・・・):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "        \"\"\"\n",
    "\n",
    "    # 問題5\n",
    "    def _loss_func(self,・・・):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        \"\"\"\n",
    "        # 問題4\n",
    "        self._mse(・・・)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e9b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.theta = np.ones((theta_n, 1))\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        #問題１　仮定関数の計算\n",
    "        y_hat = self._linear_hypothesis(self,X)\n",
    "        \n",
    "        #問題２　最急降下法によるパラメータの更新値計算\n",
    "        # = self._gradient_descent(self, X, error)\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "    #仮定関数の計算\n",
    "    def _linear_hypothesis(self,X):\n",
    "        theta_n = X.shape[1]\n",
    "        #print(self.theta)\n",
    "        #print(X)\n",
    "        y_hat = X @ self.theta\n",
    "        y_hat\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db488eb",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "$h_θ(x)=θ_0x_0+θ_1x_1+...+θ_jx_j+...+θ_nx_n.(x_0=1)$\n",
    "\n",
    "x\n",
    " : 特徴量ベクトル\n",
    "\n",
    "\n",
    "θ\n",
    " : パラメータベクトル\n",
    "\n",
    "\n",
    "n\n",
    " : 特徴量の数\n",
    "\n",
    "\n",
    "x\n",
    "j\n",
    " : j番目の特徴量\n",
    "\n",
    "\n",
    "θ\n",
    "j\n",
    " : j番目のパラメータ（重み）\n",
    "\n",
    "\n",
    "特徴量の数\n",
    "n\n",
    "は任意の値に対応できる実装にしてください。\n",
    "\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "$h_θ(x)=θ^T⋅x$\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9437c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self,X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "    Parameters\n",
    "    ---------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "    訓練データ\n",
    "     Returns\n",
    "    -------\n",
    "    次の形のndarray, shape (n_samples, 1)\n",
    "    線形の仮定関数による推定結果\n",
    "    \"\"\"\n",
    "    theta_n = X.shape[1]\n",
    "\n",
    "    print(self.theta)\n",
    "    print(X)\n",
    "    y_hat = X @ self.theta\n",
    "    y_hat"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1764ab9b",
   "metadata": {},
   "source": [
    "#問題１、トイデータで練習\n",
    "X = np.arange(10)\n",
    "theta_n = X.shape[0]\n",
    "theta = np.ones((theta_n,1))\n",
    "print(\"theta\")    \n",
    "print(theta)\n",
    "print(theta.shape)\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "y_hat =  X @ theta\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad11bb",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "$θ_j=θ_j−α\\frac{1}{m} \\sum_{i=1}^{m}[(h_θ(x^i)−y^i)x^i_j] \\quad$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$i$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$j$ : 特徴量のインデックス\n",
    "\n",
    "\n",
    "雛形\n",
    "\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。\n",
    "\n",
    "#!\n",
    "[image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85cd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#最急降下法によるパラメータの更新\n",
    "def _gradient_descent(X, y, y_hat):\n",
    "    theta_j = ([[0,0]])\n",
    "    alpha = 0.01\n",
    "    x_j = X[0]\n",
    "    \n",
    "    error = y_hat - y\n",
    "    y_pred = error @ x_j\n",
    "    \n",
    "     = self.theta - alpha * (error.T * X) / x.shape[0]\n",
    "    return self.theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec775681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[ 3. ]\n",
      " [ 5.5]\n",
      " [ 8. ]\n",
      " [10.5]\n",
      " [13. ]]\n",
      "(5, 1)\n",
      "x\n",
      "[1.   2.25 3.5  4.75 6.  ]\n",
      "(5,)\n",
      "y\n",
      "X\n",
      "[[1.   1.  ]\n",
      " [1.   2.25]\n",
      " [1.   3.5 ]\n",
      " [1.   4.75]\n",
      " [1.   6.  ]]\n",
      "(5, 2)\n",
      "y_pred\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "(5, 1)\n",
      "error\n",
      "[[ -3. ]\n",
      " [ -5.5]\n",
      " [ -8. ]\n",
      " [-10.5]\n",
      " [-13. ]]\n",
      "(5, 1)\n",
      "theta\n",
      "[[0.4    1.7125]]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([[0,0]])#\n",
    "print(theta.shape)\n",
    "\n",
    "x = np.linspace(1,6,5)\n",
    "y = 2*x + 1\n",
    "X = np.c_[np.ones(5),x]\n",
    "alpha = 0.05\n",
    "y_pred = X @ theta.T\n",
    "y = y.reshape(-1,1)\n",
    "print(y.reshape(-1,1))\n",
    "print(y.shape)\n",
    "error = y_pred - y\n",
    "\n",
    "print(\"x\")\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(\"y\")\n",
    "\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(\"y_pred\")\n",
    "y_pred\n",
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(\"error\")\n",
    "print(error)\n",
    "print(error.shape)\n",
    "\n",
    "theta = theta - alpha * (error.T @ X) / X.shape[0]\n",
    "print(\"theta\")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fda7c5df",
   "metadata": {},
   "source": [
    "def gradient_descent():\n",
    "    pass\n",
    "def fit():\n",
    "    for i in range(iter_num):\n",
    "        gradient_descent()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
